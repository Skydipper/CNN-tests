{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Google Earth Engine, Cloud Storage and AI Platform\n",
    "\n",
    "This notebook is inspired by the following tutorials:\n",
    "\n",
    "- [Getting started: Training and prediction with Keras](https://cloud.google.com/ml-engine/docs/tensorflow/getting-started-keras)\n",
    "- [Down to Earth with AI Platform](https://medium.com/google-earth/down-to-earth-with-ai-platform-7bc363abf4fa)\n",
    "- [Multi-class prediction with a DNN](https://developers.google.com/earth-engine/tf_examples#multi-class-prediction-with-a-dnn)\n",
    "- [Regression with an FCNN](https://developers.google.com/earth-engine/tf_examples#regression-with-an-fcnn)\n",
    "- [Deploying to AI Platform](https://developers.google.com/earth-engine/tf_examples#deploying-to-ai-platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup software libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.202'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and initialize the Earth Engine library.\n",
    "import ee\n",
    "ee.Initialize()\n",
    "ee.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.3\n"
     ]
    }
   ],
   "source": [
    "# Folium setup.\n",
    "import folium\n",
    "print(folium.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import functools\n",
    "import json\n",
    "from pprint import pprint\n",
    "import env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Earth Engine ImageCollection attributes\n",
    "\n",
    "We define the different attributes that we will need for each Earth Engine ImageCollection all through the notebook. \n",
    "\n",
    "We include them in the `ee_collection_specifics.py` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ee_collection_specifics.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ee_collection_specifics.py\n",
    "\n",
    "\"\"\"\n",
    "Information on Earth Engine collections stored here (e.g. bands, collection ids, etc.)\n",
    "\"\"\"\n",
    "\n",
    "import ee\n",
    "\n",
    "def ee_collections(collection):\n",
    "    \"\"\"\n",
    "    Earth Engine image collection names\n",
    "    \"\"\"\n",
    "    dic = {\n",
    "        'Sentinel-2-Top-of-Atmosphere-Reflectance': 'COPERNICUS/S2',\n",
    "        'Landsat-7-Surface-Reflectance': 'LANDSAT/LE07/C01/T1_SR',\n",
    "        'Landsat-8-Surface-Reflectance': 'LANDSAT/LC08/C01/T1_SR',\n",
    "        'USDA-NASS-Cropland-Data-Layers': 'USDA/NASS/CDL',\n",
    "        'USGS-National-Land-Cover-Database': 'USGS/NLCD',\n",
    "        'Skydipper-Water-Quality': 'projects/vizzuality/skydipper-water-quality/LWQ-100m'\n",
    "    }\n",
    "    \n",
    "    return dic[collection]\n",
    "\n",
    "def ee_bands(collection):\n",
    "    \"\"\"\n",
    "    Earth Engine band names\n",
    "    \"\"\"\n",
    "    \n",
    "    dic = {\n",
    "        'Sentinel-2-Top-of-Atmosphere-Reflectance': ['B1','B2','B3','B4','B5','B6','B7','B8A','B8','B11','B12','ndvi','ndwi'],\n",
    "        'Landsat-7-Surface-Reflectance': ['B1','B2','B3','B4','B5','B6','B7','ndvi','ndwi'],\n",
    "        'Landsat-8-Surface-Reflectance': ['B1','B2','B3','B4','B5','B6','B7','B10','B11','ndvi','ndwi'],\n",
    "        'USDA-NASS-Cropland-Data-Layers': ['landcover', 'cropland', 'land', 'water', 'urban'],\n",
    "        'USGS-National-Land-Cover-Database': ['impervious'],\n",
    "        'Skydipper-Water-Quality': ['turbidity_blended_mean']\n",
    "    }\n",
    "    \n",
    "    return dic[collection]\n",
    "\n",
    "def ee_bands_rgb(collection):\n",
    "    \"\"\"\n",
    "    Earth Engine rgb band names\n",
    "    \"\"\"\n",
    "    \n",
    "    dic = {\n",
    "        'Sentinel-2-Top-of-Atmosphere-Reflectance': ['B4','B3','B2'],\n",
    "        'Landsat-7-Surface-Reflectance': ['B3','B2','B1'],\n",
    "        'Landsat-8-Surface-Reflectance': ['B4', 'B3', 'B2'],\n",
    "        'USDA-NASS-Cropland-Data-Layers': ['landcover'],\n",
    "        'USGS-National-Land-Cover-Database': ['impervious'],\n",
    "        'Skydipper-Water-Quality': ['turbidity_blended_mean']\n",
    "    }\n",
    "    \n",
    "    return dic[collection]\n",
    "\n",
    "def ee_bands_normThreshold(collection):\n",
    "    \"\"\"\n",
    "    Normalization threshold percentage\n",
    "    \"\"\"\n",
    "    \n",
    "    dic = {\n",
    "        'Sentinel-2-Top-of-Atmosphere-Reflectance': {'B1': 75,'B2': 75,'B3': 75,'B4': 75,'B5': 80,'B6': 80,'B7': 80,'B8A': 80,'B8': 80,'B11': 100,'B12': 100},\n",
    "        'Landsat-7-Surface-Reflectance': {'B1': 95,'B2': 95,'B3': 95,'B4': 100,'B5': 100,'B6': 100,'B7': 100},\n",
    "        'Landsat-8-Surface-Reflectance': {'B1': 90,'B2': 95,'B3': 95,'B4': 95,'B5': 100,'B6': 100,'B7': 100,'B10': 100,'B11': 100},\n",
    "        'USDA-NASS-Cropland-Data-Layers': {'landcover': 100, 'cropland': 100, 'land': 100, 'water': 100, 'urban': 100},\n",
    "        'USGS-National-Land-Cover-Database': {'impervious': 100},\n",
    "        'Skydipper-Water-Quality': {'turbidity_blended_mean': 100}\n",
    "    }\n",
    "    \n",
    "    return dic[collection]\n",
    "\n",
    "def normalize(collection):\n",
    "    dic = {\n",
    "        'Sentinel-2-Top-of-Atmosphere-Reflectance': True,\n",
    "        'Landsat-7-Surface-Reflectance': True,\n",
    "        'Landsat-8-Surface-Reflectance': True,\n",
    "        'USDA-NASS-Cropland-Data-Layers': False,\n",
    "        'USGS-National-Land-Cover-Database': False,\n",
    "        'Skydipper-Water-Quality': False\n",
    "    }\n",
    "    \n",
    "    return dic[collection]\n",
    "\n",
    "def vizz_params_rgb(collection):\n",
    "    \"\"\"\n",
    "    Visualization parameters\n",
    "    \"\"\"\n",
    "    dic = {\n",
    "        'Sentinel-2-Top-of-Atmosphere-Reflectance': {'min':0,'max':3000, 'bands':['B4','B3','B2']},\n",
    "        'Landsat-7-Surface-Reflectance': {'min':0,'max':3000, 'gamma':1.4, 'bands':['B3','B2','B1']},\n",
    "        'Landsat-8-Surface-Reflectance': {'min':0,'max':3000, 'gamma':1.4, 'bands':['B4','B3','B2']},\n",
    "        'USDA-NASS-Cropland-Data-Layers': {'min':0,'max':3, 'bands':['landcover']},\n",
    "        'USGS-National-Land-Cover-Database': {'min': 0, 'max': 1, 'bands':['impervious']},\n",
    "        'Skydipper-Water-Quality': {'min': 0, 'max': 1, 'bands':['turbidity_blended_mean']}\n",
    "    }\n",
    "    \n",
    "    return dic[collection]\n",
    "\n",
    "def vizz_params(collection):\n",
    "    \"\"\"\n",
    "    Visualization parameters\n",
    "    \"\"\"\n",
    "    dic = {\n",
    "        'Sentinel-2-Top-of-Atmosphere-Reflectance': [{'min':0,'max':1, 'bands':['B4','B3','B2']}, \n",
    "                      {'min':0,'max':1, 'bands':['B1']},\n",
    "                      {'min':0,'max':1, 'bands':['B5']},\n",
    "                      {'min':0,'max':1, 'bands':['B6']},\n",
    "                      {'min':0,'max':1, 'bands':['B7']},\n",
    "                      {'min':0,'max':1, 'bands':['B8A']},\n",
    "                      {'min':0,'max':1, 'bands':['B8']},\n",
    "                      {'min':0,'max':1, 'bands':['B11']},\n",
    "                      {'min':0,'max':1, 'bands':['B12']},\n",
    "                      {'min':0,'max':1, 'gamma':1.4, 'bands':['ndvi']},\n",
    "                      {'min':0,'max':1, 'gamma':1.4, 'bands':['ndwi']}],\n",
    "        'Landsat-7-Surface-Reflectance': [{'min':0,'max':1, 'gamma':1.4, 'bands':['B3','B2','B1']}, \n",
    "                     {'min':0,'max':1, 'gamma':1.4, 'bands':['B4']},\n",
    "                     {'min':0,'max':1, 'gamma':1.4, 'bands':['B5']},\n",
    "                     {'min':0,'max':1, 'gamma':1.4, 'bands':['B7']},\n",
    "                     {'min':0,'max':1, 'gamma':1.4, 'bands':['B6']},\n",
    "                     {'min':0,'max':1, 'gamma':1.4, 'bands':['ndvi']},\n",
    "                     {'min':0,'max':1, 'gamma':1.4, 'bands':['ndwi']}],\n",
    "        'Landsat-8-Surface-Reflectance': [{'min':0,'max':1, 'gamma':1.4, 'bands':['B4','B3','B2']}, \n",
    "                     {'min':0,'max':1, 'gamma':1.4, 'bands':['B1']},\n",
    "                     {'min':0,'max':1, 'gamma':1.4, 'bands':['B5']},\n",
    "                     {'min':0,'max':1, 'gamma':1.4, 'bands':['B6']},\n",
    "                     {'min':0,'max':1, 'gamma':1.4, 'bands':['B7']},\n",
    "                     {'min':0,'max':1, 'gamma':1.4, 'bands':['B10']},\n",
    "                     {'min':0,'max':1, 'gamma':1.4, 'bands':['B11']},\n",
    "                     {'min':0,'max':1, 'gamma':1.4, 'bands':['ndvi']},\n",
    "                     {'min':0,'max':1, 'gamma':1.4, 'bands':['ndwi']}],\n",
    "        'USDA-NASS-Cropland-Data-Layers': [{'min':0,'max':3, 'bands':['landcover']},\n",
    "                               {'min':0,'max':1, 'bands':['cropland']},\n",
    "                               {'min':0,'max':1, 'bands':['land']},\n",
    "                               {'min':0,'max':1, 'bands':['water']},\n",
    "                               {'min':0,'max':1, 'bands':['urban']}],\n",
    "        'USGS-National-Land-Cover-Database': [{'min': 0, 'max': 1, 'bands':['impervious']}],\n",
    "        'Skydipper-Water-Quality': [{'min': 0, 'max': 1, 'bands':['turbidity_blended_mean']}],\n",
    "        \n",
    "    }\n",
    "    \n",
    "    return dic[collection]\n",
    "\n",
    "## ------------------------- Filter datasets ------------------------- ##\n",
    "## Lansat 7 Cloud Free Composite\n",
    "def CloudMaskL7sr(image):\n",
    "    qa = image.select('pixel_qa')\n",
    "    #If the cloud bit (5) is set and the cloud confidence (7) is high\n",
    "    #or the cloud shadow bit is set (3), then it's a bad pixel.\n",
    "    cloud = qa.bitwiseAnd(1 << 5).And(qa.bitwiseAnd(1 << 7)).Or(qa.bitwiseAnd(1 << 3))\n",
    "    #Remove edge pixels that don't occur in all bands\n",
    "    mask2 = image.mask().reduce(ee.Reducer.min())\n",
    "    return image.updateMask(cloud.Not()).updateMask(mask2)\n",
    "\n",
    "def CloudFreeCompositeL7(startDate, stopDate):\n",
    "    ## Define your collection\n",
    "    collection = ee.ImageCollection('LANDSAT/LE07/C01/T1_SR')\n",
    "\n",
    "    ## Filter \n",
    "    collection = collection.filterDate(startDate,stopDate).map(CloudMaskL7sr)\n",
    "\n",
    "    ## Composite\n",
    "    composite = collection.median()\n",
    "    \n",
    "    ## normDiff bands\n",
    "    normDiff_band_names = ['ndvi', 'ndwi']\n",
    "    for nB, normDiff_band in enumerate([['B4','B3'], ['B4','B2']]):\n",
    "        image_nd = composite.normalizedDifference(normDiff_band).rename(normDiff_band_names[nB])\n",
    "        composite = ee.Image.cat([composite, image_nd])\n",
    "    \n",
    "    return composite\n",
    "\n",
    "## Lansat 8 Cloud Free Composite\n",
    "def CloudMaskL8sr(image):\n",
    "    opticalBands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
    "    thermalBands = ['B10', 'B11']\n",
    "\n",
    "    cloudShadowBitMask = ee.Number(2).pow(3).int()\n",
    "    cloudsBitMask = ee.Number(2).pow(5).int()\n",
    "    qa = image.select('pixel_qa')\n",
    "    mask1 = qa.bitwiseAnd(cloudShadowBitMask).eq(0).And(\n",
    "    qa.bitwiseAnd(cloudsBitMask).eq(0))\n",
    "    mask2 = image.mask().reduce('min')\n",
    "    mask3 = image.select(opticalBands).gt(0).And(\n",
    "            image.select(opticalBands).lt(10000)).reduce('min')\n",
    "    mask = mask1.And(mask2).And(mask3)\n",
    "    \n",
    "    return image.updateMask(mask)\n",
    "\n",
    "def CloudFreeCompositeL8(startDate, stopDate):\n",
    "    ## Define your collection\n",
    "    collection = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')\n",
    "\n",
    "    ## Filter \n",
    "    collection = collection.filterDate(startDate,stopDate).map(CloudMaskL8sr)\n",
    "\n",
    "    ## Composite\n",
    "    composite = collection.median()\n",
    "    \n",
    "    ## normDiff bands\n",
    "    normDiff_band_names = ['ndvi', 'ndwi']\n",
    "    for nB, normDiff_band in enumerate([['B5','B4'], ['B5','B3']]):\n",
    "        image_nd = composite.normalizedDifference(normDiff_band).rename(normDiff_band_names[nB])\n",
    "        composite = ee.Image.cat([composite, image_nd])\n",
    "    \n",
    "    return composite\n",
    "\n",
    "## Sentinel 2 Cloud Free Composite\n",
    "def CloudMaskS2(image):\n",
    "    \"\"\"\n",
    "    European Space Agency (ESA) clouds from 'QA60', i.e. Quality Assessment band at 60m\n",
    "    parsed by Nick Clinton\n",
    "    \"\"\"\n",
    "    AerosolsBands = ['B1']\n",
    "    VIBands = ['B2', 'B3', 'B4']\n",
    "    RedBands = ['B5', 'B6', 'B7', 'B8A']\n",
    "    NIRBands = ['B8']\n",
    "    SWIRBands = ['B11', 'B12']\n",
    "\n",
    "    qa = image.select('QA60')\n",
    "\n",
    "    # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "    cloudBitMask = int(2**10)\n",
    "    cirrusBitMask = int(2**11)\n",
    "\n",
    "    # Both flags set to zero indicates clear conditions.\n",
    "    mask = qa.bitwiseAnd(cloudBitMask).eq(0).And(\\\n",
    "            qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "\n",
    "    return image.updateMask(mask)\n",
    "\n",
    "def CloudFreeCompositeS2(startDate, stopDate):\n",
    "    ## Define your collection\n",
    "    collection = ee.ImageCollection('COPERNICUS/S2')\n",
    "\n",
    "    ## Filter \n",
    "    collection = collection.filterDate(startDate,stopDate)\\\n",
    "            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\\\n",
    "            .map(CloudMaskS2)\n",
    "\n",
    "    ## Composite\n",
    "    composite = collection.median()\n",
    "    \n",
    "    ## normDiff bands\n",
    "    normDiff_band_names = ['ndvi', 'ndwi']\n",
    "    for nB, normDiff_band in enumerate([['B8','B4'], ['B8','B3']]):\n",
    "        image_nd = composite.normalizedDifference(normDiff_band).rename(normDiff_band_names[nB])\n",
    "        composite = ee.Image.cat([composite, image_nd])\n",
    "    \n",
    "    return composite\n",
    "\n",
    "## Cropland Data Layers\n",
    "def CroplandData(startDate, stopDate):\n",
    "    ## Define your collection\n",
    "    collection = ee.ImageCollection('USDA/NASS/CDL')\n",
    "\n",
    "    ## Filter \n",
    "    collection = collection.filterDate(startDate,stopDate)\n",
    "\n",
    "    ## First image\n",
    "    image = ee.Image(collection.first())\n",
    "    \n",
    "    ## Change classes\n",
    "    land = ['65', '131', '141', '142', '143', '152', '176', '87', '190', '195']\n",
    "    water = ['83', '92', '111']\n",
    "    urban = ['82', '121', '122', '123', '124']\n",
    "    \n",
    "    classes = []\n",
    "    for n, i in enumerate([land,water,urban]):\n",
    "        a = ''\n",
    "        for m, j in enumerate(i):\n",
    "            if m < len(i)-1:\n",
    "                a = a + 'crop == '+ j + ' || '\n",
    "            else: \n",
    "                a = a + 'crop == '+ j\n",
    "        classes.append('('+a+') * '+str(n+1))\n",
    "    classes = ' + '.join(classes)\n",
    "    \n",
    "    image = image.expression(classes, {'crop': image.select(['cropland'])})\n",
    "    \n",
    "    image =image.rename('landcover')\n",
    "    \n",
    "    # Split image into 1 band per class\n",
    "    names = ['cropland', 'land', 'water', 'urban']\n",
    "    mask = image\n",
    "    for i, name in enumerate(names):\n",
    "        image = ee.Image.cat([image, mask.eq(i).rename(name)])\n",
    "     \n",
    "    return image\n",
    "\n",
    "## National Land Cover Database\n",
    "def ImperviousData(startDate, stopDate):\n",
    "    ## Define your collection\n",
    "    collection = ee.ImageCollection('USGS/NLCD')\n",
    "\n",
    "    ## Filter \n",
    "    collection = collection.filterDate(startDate,stopDate)\n",
    "\n",
    "    ## First image\n",
    "    image = ee.Image(collection.first())\n",
    "    \n",
    "    ## Select impervious band\n",
    "    image = image.select('impervious')\n",
    "    \n",
    "    ## Normalize to 1\n",
    "    image = image.divide(100).float()\n",
    "    \n",
    "    return image\n",
    "\n",
    "def WaterQuality(startDate, stopDate):\n",
    "    ## Define your collection\n",
    "    collection = ee.ImageCollection('projects/vizzuality/skydipper-water-quality/LWQ-100m')\n",
    "\n",
    "    ## Filter \n",
    "    collection = collection.filterDate(startDate,stopDate)\n",
    "\n",
    "    ## First image\n",
    "    image = ee.Image(collection.first())\n",
    "    \n",
    "    ## Select impervious band\n",
    "    image = image.select('turbidity_blended_mean')\n",
    "    \n",
    "    return image\n",
    "\n",
    "## ------------------------------------------------------------------- ##\n",
    "\n",
    "def Composite(collection):\n",
    "    dic = {\n",
    "        'Sentinel-2-Top-of-Atmosphere-Reflectance': CloudFreeCompositeS2,\n",
    "        'Landsat-7-Surface-Reflectance': CloudFreeCompositeL7,\n",
    "        'Landsat-8-Surface-Reflectance': CloudFreeCompositeL8,\n",
    "        'USDA-NASS-Cropland-Data-Layers': CroplandData,\n",
    "        'USGS-National-Land-Cover-Database': ImperviousData,\n",
    "        'Skydipper-Water-Quality': WaterQuality\n",
    "    }\n",
    "    \n",
    "    return dic[collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee_collection_specifics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composite image\n",
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = 'USDA-NASS-Cropland-Data-Layers'\n",
    "startDate = '2016-01-01'\n",
    "stopDate = '2016-12-31'\n",
    "scale = 30 #scale in meters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display composite**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x1133e66d8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the URL format used for Earth Engine generated map tiles.\n",
    "EE_TILES = 'https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}'\n",
    "\n",
    "composite = ee_collection_specifics.Composite(collection)(startDate, stopDate)\n",
    "mapid = composite.getMapId(ee_collection_specifics.vizz_params_rgb(collection))\n",
    "\n",
    "tiles_url = EE_TILES.format(**mapid)\n",
    "\n",
    "map = folium.Map(location=[34.093568352499986, -118.46832275390466])\n",
    "folium.TileLayer(\n",
    "tiles=tiles_url,\n",
    "attr='Google Earth Engine',\n",
    "overlay=True,\n",
    "name=str(ee_collection_specifics.ee_bands_rgb(collection))).add_to(map)\n",
    "    \n",
    "map.add_child(folium.LayerControl())\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Geostore\n",
    "\n",
    "We select the areas from which we will export the training data.\n",
    "\n",
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outCollection = 'USDA-NASS-Cropland-Data-Layers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygons_to_multipoligon(polygons):\n",
    "    multipoligon = []\n",
    "    MultiPoligon = {}\n",
    "    for polygon in polygons.get('features'):\n",
    "        multipoligon.append(polygon.get('geometry').get('coordinates'))\n",
    "        \n",
    "    MultiPoligon = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": [\n",
    "            {\n",
    "                \"type\": \"Feature\",\n",
    "                \"properties\": {},\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"MultiPolygon\",\n",
    "                    \"coordinates\":  multipoligon\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return MultiPoligon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if outCollection == 'USGS-National-Land-Cover-Database':\n",
    "    trainPolygons = {\"type\":\"FeatureCollection\",\"features\":[{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-123.22265625000001,45.213003555993964],[-122.03613281249999,45.213003555993964],[-122.03613281249999,46.164614496897094],[-123.22265625000001,46.164614496897094],[-123.22265625000001,45.213003555993964]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-122.1240234375,38.16911413556086],[-120.76171875,38.16911413556086],[-120.76171875,39.13006024213511],[-122.1240234375,39.13006024213511],[-122.1240234375,38.16911413556086]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-119.70703125,34.77771580360469],[-118.3447265625,34.77771580360469],[-118.3447265625,35.92464453144099],[-119.70703125,35.92464453144099],[-119.70703125,34.77771580360469]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-115.97167968750001,35.496456056584165],[-114.521484375,35.496456056584165],[-114.521484375,36.73888412439431],[-115.97167968750001,36.73888412439431],[-115.97167968750001,35.496456056584165]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-118.21289062499999,33.797408767572485],[-116.23535156249999,33.797408767572485],[-116.23535156249999,34.379712580462204],[-118.21289062499999,34.379712580462204],[-118.21289062499999,33.797408767572485]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-112.6318359375,33.02708758002874],[-111.4013671875,33.02708758002874],[-111.4013671875,34.016241889667015],[-112.6318359375,34.016241889667015],[-112.6318359375,33.02708758002874]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-105.6005859375,39.40224434029275],[-104.5458984375,39.40224434029275],[-104.5458984375,40.44694705960048],[-105.6005859375,40.44694705960048],[-105.6005859375,39.40224434029275]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-112.67578124999999,40.27952566881291],[-111.4453125,40.27952566881291],[-111.4453125,41.21172151054787],[-112.67578124999999,41.21172151054787],[-112.67578124999999,40.27952566881291]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-97.734375,32.21280106801518],[-95.9326171875,32.21280106801518],[-95.9326171875,33.32134852669881],[-97.734375,33.32134852669881],[-97.734375,32.21280106801518]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-99.36035156249999,29.036960648558267],[-97.822265625,29.036960648558267],[-97.822265625,30.031055426540206],[-99.36035156249999,30.031055426540206],[-99.36035156249999,29.036960648558267]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-95.185546875,38.61687046392973],[-93.9990234375,38.61687046392973],[-93.9990234375,39.639537564366684],[-95.185546875,39.639537564366684],[-95.185546875,38.61687046392973]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-91.2744140625,38.30718056188316],[-89.6484375,38.30718056188316],[-89.6484375,39.16414104768742],[-91.2744140625,39.16414104768742],[-91.2744140625,38.30718056188316]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-88.330078125,41.343824581185686],[-86.8798828125,41.343824581185686],[-86.8798828125,42.391008609205045],[-88.330078125,42.391008609205045],[-88.330078125,41.343824581185686]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-93.91113281249999,44.49650533109348],[-92.5048828125,44.49650533109348],[-92.5048828125,45.583289756006316],[-93.91113281249999,45.583289756006316],[-93.91113281249999,44.49650533109348]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-81.38671875,34.813803317113155],[-80.2880859375,34.813803317113155],[-80.2880859375,35.782170703266075],[-81.38671875,35.782170703266075],[-81.38671875,34.813803317113155]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-85.0341796875,33.17434155100208],[-83.7158203125,33.17434155100208],[-83.7158203125,34.27083595165],[-85.0341796875,34.27083595165],[-85.0341796875,33.17434155100208]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-87.2314453125,35.60371874069731],[-86.17675781249999,35.60371874069731],[-86.17675781249999,36.63316209558658],[-87.2314453125,36.63316209558658],[-87.2314453125,35.60371874069731]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-87.14355468749999,32.91648534731439],[-86.2646484375,32.91648534731439],[-86.2646484375,33.97980872872457],[-87.14355468749999,33.97980872872457],[-87.14355468749999,32.91648534731439]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-81.9140625,27.566721430409707],[-81.03515625,27.566721430409707],[-81.03515625,28.844673680771795],[-81.9140625,28.844673680771795],[-81.9140625,27.566721430409707]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-84.7705078125,38.92522904714054],[-83.75976562499999,38.92522904714054],[-83.75976562499999,40.17887331434696],[-84.7705078125,40.17887331434696],[-84.7705078125,38.92522904714054]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-80.947265625,40.27952566881291],[-79.98046875,40.27952566881291],[-79.98046875,41.178653972331674],[-80.947265625,41.178653972331674],[-80.947265625,40.27952566881291]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-75.2783203125,40.613952441166596],[-73.8720703125,40.613952441166596],[-73.8720703125,41.21172151054787],[-75.2783203125,41.21172151054787],[-75.2783203125,40.613952441166596]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-78.0908203125,38.44498466889473],[-76.728515625,38.44498466889473],[-76.728515625,39.33429742980725],[-78.0908203125,39.33429742980725],[-78.0908203125,38.44498466889473]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-112.6318359375,46.164614496897094],[-111.4453125,46.164614496897094],[-111.4453125,46.86019101567027],[-112.6318359375,46.86019101567027],[-112.6318359375,46.164614496897094]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-117.1142578125,43.229195113965005],[-115.57617187499999,43.229195113965005],[-115.57617187499999,44.08758502824516],[-117.1142578125,44.08758502824516],[-117.1142578125,43.229195113965005]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-96.328125,35.746512259918504],[-95.2734375,35.746512259918504],[-95.2734375,36.4566360115962],[-96.328125,36.4566360115962],[-96.328125,35.746512259918504]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-98.173828125,35.02999636902566],[-96.9873046875,35.02999636902566],[-96.9873046875,35.817813158696616],[-98.173828125,35.817813158696616],[-98.173828125,35.02999636902566]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-92.6806640625,34.379712580462204],[-91.7578125,34.379712580462204],[-91.7578125,35.10193405724606],[-92.6806640625,35.10193405724606],[-92.6806640625,34.379712580462204]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-90.7470703125,34.63320791137959],[-89.3408203125,34.63320791137959],[-89.3408203125,35.71083783530009],[-90.7470703125,35.71083783530009],[-90.7470703125,34.63320791137959]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-107.314453125,34.74161249883172],[-106.12792968749999,34.74161249883172],[-106.12792968749999,35.60371874069731],[-107.314453125,35.60371874069731],[-107.314453125,34.74161249883172]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-94.3505859375,41.1455697310095],[-92.94433593749999,41.1455697310095],[-92.94433593749999,42.19596877629178],[-94.3505859375,42.19596877629178],[-94.3505859375,41.1455697310095]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-85.869140625,40.68063802521456],[-84.5947265625,40.68063802521456],[-84.5947265625,41.64007838467894],[-85.869140625,41.64007838467894],[-85.869140625,40.68063802521456]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-87.099609375,39.30029918615029],[-85.6494140625,39.30029918615029],[-85.6494140625,40.245991504199026],[-87.099609375,40.245991504199026],[-87.099609375,39.30029918615029]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-117.7734375,47.30903424774781],[-116.103515625,47.30903424774781],[-116.103515625,48.1367666796927],[-117.7734375,48.1367666796927],[-117.7734375,47.30903424774781]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-97.91015624999999,37.3002752813443],[-96.8115234375,37.3002752813443],[-96.8115234375,38.09998264736481],[-97.91015624999999,38.09998264736481],[-97.91015624999999,37.3002752813443]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-94.06494140625,32.25926542645933],[-93.4716796875,32.25926542645933],[-93.4716796875,32.7872745269555],[-94.06494140625,32.7872745269555],[-94.06494140625,32.25926542645933]]]}}]}  \n",
    "    trainPolys = polygons_to_multipoligon(trainPolygons)\n",
    "    \n",
    "    evalPolygons = {\"type\":\"FeatureCollection\",\"features\":[{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-95.888671875,29.38217507514529],[-95.06469726562499,29.38217507514529],[-95.06469726562499,30.12612436422458],[-95.888671875,30.12612436422458],[-95.888671875,29.38217507514529]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-83.84765625,42.374778361114195],[-82.94677734375,42.374778361114195],[-82.94677734375,42.78733853171998],[-83.84765625,42.78733853171998],[-83.84765625,42.374778361114195]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-96.88568115234375,40.69521661351714],[-95.77606201171875,40.69521661351714],[-95.77606201171875,41.393294288784865],[-96.88568115234375,41.393294288784865],[-96.88568115234375,40.69521661351714]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-105.05126953124999,38.57393751557591],[-104.490966796875,38.57393751557591],[-104.490966796875,39.0831721934762],[-105.05126953124999,39.0831721934762],[-105.05126953124999,38.57393751557591]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-122.62390136718749,46.95776134668866],[-121.84936523437499,46.95776134668866],[-121.84936523437499,48.04136507445029],[-122.62390136718749,48.04136507445029],[-122.62390136718749,46.95776134668866]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-120.157470703125,36.465471886798134],[-119.24560546875001,36.465471886798134],[-119.24560546875001,37.03763967977139],[-120.157470703125,37.03763967977139],[-120.157470703125,36.465471886798134]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-120.02563476562501,39.33854604847979],[-119.55871582031251,39.33854604847979],[-119.55871582031251,39.7240885773337],[-120.02563476562501,39.7240885773337],[-120.02563476562501,39.33854604847979]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-86.30859375,37.61423141542417],[-84.9462890625,37.61423141542417],[-84.9462890625,38.65119833229951],[-86.30859375,38.65119833229951],[-86.30859375,37.61423141542417]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-78.31054687499999,36.914764288955936],[-76.86035156249999,36.914764288955936],[-76.86035156249999,38.03078569382294],[-78.31054687499999,38.03078569382294],[-78.31054687499999,36.914764288955936]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-102.87597656249999,31.541089879585808],[-101.4697265625,31.541089879585808],[-101.4697265625,32.24997445586331],[-102.87597656249999,32.24997445586331],[-102.87597656249999,31.541089879585808]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-83.5400390625,39.50404070558415],[-82.177734375,39.50404070558415],[-82.177734375,40.54720023441049],[-83.5400390625,40.54720023441049],[-83.5400390625,39.50404070558415]]]}}]}\n",
    "    evalPolys = polygons_to_multipoligon(evalPolygons)\n",
    "    \n",
    "if outCollection == 'USDA-NASS-Cropland-Data-Layers':\n",
    "    trainPolys = {\n",
    "      \"type\": \"FeatureCollection\",\n",
    "      \"features\": [\n",
    "        {\n",
    "          \"type\": \"Feature\",\n",
    "          \"properties\": {},\n",
    "          \"geometry\": {\n",
    "            \"type\": \"MultiPolygon\",\n",
    "            \"coordinates\":  [\n",
    "    [[[  -122.882080078125,  40.50126945841645],[  -122.1240234375,  40.50126945841645],[  -122.1240234375,  41.008920735004885],[  -122.882080078125,  41.008920735004885],[  -122.882080078125,  40.50126945841645]]],\n",
    "    [[[  -122.2283935546875,  39.00637903337455],[  -121.607666015625,  39.00637903337455],[  -121.607666015625,  39.46588451142044],[  -122.2283935546875,  39.46588451142044],[  -122.2283935546875,  39.00637903337455]]],\n",
    "    [[[  -120.355224609375,  38.77978137804918],[  -119.608154296875,  38.77978137804918],[  -119.608154296875,  39.342794408952365],[  -120.355224609375,  39.342794408952365],[  -120.355224609375,  38.77978137804918]]],\n",
    "    [[[  -121.90979003906249,  37.70555348721583],[  -120.9814453125,  37.70555348721583],[  -120.9814453125,  38.39764411353178],[  -121.90979003906249,  38.39764411353178],[  -121.90979003906249,  37.70555348721583]]],\n",
    "    [[[  -120.03662109374999,  37.45741810262938],[  -119.1851806640625,  37.45741810262938],[  -119.1851806640625,  38.08268954483802],[  -120.03662109374999,  38.08268954483802],[  -120.03662109374999,  37.45741810262938]]],\n",
    "    [[[  -120.03662109374999,  37.45741810262938],[  -119.1851806640625,  37.45741810262938],[  -119.1851806640625,  38.08268954483802],[  -120.03662109374999,  38.08268954483802],[  -120.03662109374999,  37.45741810262938]]],\n",
    "    [[[  -120.03662109374999,  37.45741810262938],[  -119.1851806640625,  37.45741810262938],[  -119.1851806640625,  38.08268954483802],[  -120.03662109374999,  38.08268954483802],[  -120.03662109374999,  37.45741810262938]]],\n",
    "    [[[  -112.554931640625,  33.0178760185549],[  -111.588134765625,  33.0178760185549],[  -111.588134765625,  33.78827853625996],[  -112.554931640625,  33.78827853625996],[  -112.554931640625,  33.0178760185549]]],\n",
    "    [[[  -112.87353515625,  40.51379915504413],[  -111.829833984375,  40.51379915504413],[  -111.829833984375,  41.28606238749825],[  -112.87353515625,  41.28606238749825],[  -112.87353515625,  40.51379915504413]]],\n",
    "    [[[  -108.19335937499999,  39.095962936305476],[  -107.1826171875,  39.095962936305476],[  -107.1826171875,  39.85915479295669],[  -108.19335937499999,  39.85915479295669],[  -108.19335937499999,  39.095962936305476]]],\n",
    "    [[[  -124.25537109375,  30.86451022625836],[  -124.25537109375,  30.86451022625836],[  -124.25537109375,  30.86451022625836],[  -124.25537109375,  30.86451022625836]]],\n",
    "    [[[  -106.875,  37.142803443716836],[  -105.49072265625,  37.142803443716836],[  -105.49072265625,  38.18638677411551],[  -106.875,  38.18638677411551],[  -106.875,  37.142803443716836]]],\n",
    "    [[[  -117.31201171875001,  43.27720532212024],[  -116.01562499999999,  43.27720532212024],[  -116.01562499999999,  44.134913443750726],[  -117.31201171875001,  44.134913443750726],[  -117.31201171875001,  43.27720532212024]]],\n",
    "    [[[  -115.7080078125,  44.69989765840318],[  -114.7412109375,  44.69989765840318],[  -114.7412109375,  45.36758436884978],[  -115.7080078125,  45.36758436884978],[  -115.7080078125,  44.69989765840318]]],\n",
    "    [[[  -120.65185546875,  47.517200697839414],[  -119.33349609375,  47.517200697839414],[  -119.33349609375,  48.32703913063476],[  -120.65185546875,  48.32703913063476],[  -120.65185546875,  47.517200697839414]]],\n",
    "    [[[  -119.83886718750001,  45.69083283645816],[  -118.38867187500001,  45.69083283645816],[  -118.38867187500001,  46.694667307773116],[  -119.83886718750001,  46.694667307773116],[  -119.83886718750001,  45.69083283645816]]],\n",
    "    [[[  -107.09472656249999,  47.45780853075031],[  -105.84228515625,  47.45780853075031],[  -105.84228515625,  48.31242790407178],[  -107.09472656249999,  48.31242790407178],[  -107.09472656249999,  47.45780853075031]]],\n",
    "    [[[  -101.57958984375,  46.93526088057719],[  -100.107421875,  46.93526088057719],[  -100.107421875,  47.945786463687185],[  -101.57958984375,  47.945786463687185],[  -101.57958984375,  46.93526088057719]]],\n",
    "    [[[  -101.162109375,  44.32384807250689],[  -99.7119140625,  44.32384807250689],[  -99.7119140625,  45.22848059584359],[  -101.162109375,  45.22848059584359],[  -101.162109375,  44.32384807250689]]],\n",
    "    [[[  -100.5908203125,  41.261291493919884],[  -99.25048828124999,  41.261291493919884],[  -99.25048828124999,  42.114523952464246],[  -100.5908203125,  42.114523952464246],[  -100.5908203125,  41.261291493919884]]],\n",
    "    [[[  -97.9541015625,  37.142803443716836],[  -96.65771484375,  37.142803443716836],[  -96.65771484375,  38.13455657705411],[  -97.9541015625,  38.13455657705411],[  -97.9541015625,  37.142803443716836]]],\n",
    "    [[[  -112.78564453124999,  32.91648534731439],[  -111.357421875,  32.91648534731439],[  -111.357421875,  33.925129700072],[  -112.78564453124999,  33.925129700072],[  -112.78564453124999,  32.91648534731439]]],\n",
    "    [[[  -106.435546875,  35.15584570226544],[  -105.22705078125,  35.15584570226544],[  -105.22705078125,  36.13787471840729],[  -106.435546875,  36.13787471840729],[  -106.435546875,  35.15584570226544]]],\n",
    "    [[[  -97.3828125,  32.45415593941475],[  -96.2841796875,  32.45415593941475],[  -96.2841796875,  33.22949814144951],[  -97.3828125,  33.22949814144951],[  -97.3828125,  32.45415593941475]]],\n",
    "    [[[  -97.97607421875,  35.04798673426734],[  -97.00927734375,  35.04798673426734],[  -97.00927734375,  35.764343479667176],[  -97.97607421875,  35.764343479667176],[  -97.97607421875,  35.04798673426734]]],\n",
    "    [[[  -97.97607421875,  35.04798673426734],[  -97.00927734375,  35.04798673426734],[  -97.00927734375,  35.764343479667176],[  -97.97607421875,  35.764343479667176],[  -97.97607421875,  35.04798673426734]]],\n",
    "    [[[  -95.4052734375,  47.62097541515849],[  -94.24072265625,  47.62097541515849],[  -94.24072265625,  48.28319289548349],[  -95.4052734375,  48.28319289548349],[  -95.4052734375,  47.62097541515849]]],\n",
    "    [[[  -94.19677734375,  41.27780646738183],[  -93.09814453125,  41.27780646738183],[  -93.09814453125,  42.13082130188811],[  -94.19677734375,  42.13082130188811],[  -94.19677734375,  41.27780646738183]]],\n",
    "    [[[  -93.71337890625,  37.75334401310656],[  -92.6806640625,  37.75334401310656],[  -92.6806640625,  38.51378825951165],[  -93.71337890625,  38.51378825951165],[  -93.71337890625,  37.75334401310656]]],\n",
    "    [[[  -90.63720703125,  34.615126683462194],[  -89.47265625,  34.615126683462194],[  -89.47265625,  35.69299463209881],[  -90.63720703125,  35.69299463209881],[  -90.63720703125,  34.615126683462194]]],\n",
    "    [[[  -93.05419921875,  30.44867367928756],[  -91.77978515625,  30.44867367928756],[  -91.77978515625,  31.57853542647338],[  -93.05419921875,  31.57853542647338],[  -93.05419921875,  30.44867367928756]]],\n",
    "    [[[  -90.02197265625,  44.276671273775186],[  -88.59374999999999,  44.276671273775186],[  -88.59374999999999,  44.98034238084973],[  -90.02197265625,  44.98034238084973],[  -90.02197265625,  44.276671273775186]]],\n",
    "    [[[  -90.63720703125,  38.41055825094609],[  -89.49462890625,  38.41055825094609],[  -89.49462890625,  39.18117526158749],[  -90.63720703125,  39.18117526158749],[  -90.63720703125,  38.41055825094609]]],\n",
    "    [[[  -87.56103515625,  35.62158189955968],[  -86.28662109375,  35.62158189955968],[  -86.28662109375,  36.4566360115962],[  -87.56103515625,  36.4566360115962],[  -87.56103515625,  35.62158189955968]]],\n",
    "    [[[  -90.63720703125,  31.93351676190369],[  -89.49462890625,  31.93351676190369],[  -89.49462890625,  32.731840896865684],[  -90.63720703125,  32.731840896865684],[  -90.63720703125,  31.93351676190369]]],\n",
    "    [[[  -69.54345703125,  44.68427737181225],[  -68.5107421875,  44.68427737181225],[  -68.5107421875,  45.336701909968134],[  -69.54345703125,  45.336701909968134],[  -69.54345703125,  44.68427737181225]]],\n",
    "    [[[  -73.212890625,  41.49212083968776],[  -72.35595703125,  41.49212083968776],[  -72.35595703125,  42.032974332441405],[  -73.212890625,  42.032974332441405],[  -73.212890625,  41.49212083968776]]],\n",
    "    [[[  -77.93701171875,  38.70265930723801],[  -76.97021484375,  38.70265930723801],[  -76.97021484375,  39.26628442213066],[  -77.93701171875,  39.26628442213066],[  -77.93701171875,  38.70265930723801]]],\n",
    "    [[[  -79.25537109375,  35.44277092585766],[  -78.15673828125,  35.44277092585766],[  -78.15673828125,  36.13787471840729],[  -79.25537109375,  36.13787471840729],[  -79.25537109375,  35.44277092585766]]],\n",
    "    [[[  -81.4306640625,  33.55970664841198],[  -80.44189453125,  33.55970664841198],[  -80.44189453125,  34.288991865037524],[  -81.4306640625,  34.288991865037524],[  -81.4306640625,  33.55970664841198]]],\n",
    "    [[[  -84.90234375,  33.394759218577995],[  -83.91357421875,  33.394759218577995],[  -83.91357421875,  34.19817309627726],[  -84.90234375,  34.19817309627726],[  -84.90234375,  33.394759218577995]]],\n",
    "    [[[  -82.28759765625,  28.246327971048842],[  -81.2548828125,  28.246327971048842],[  -81.2548828125,  29.209713225868185],[  -82.28759765625,  29.209713225868185],[  -82.28759765625,  28.246327971048842]]],\n",
    "    [[[  -109.88525390624999,  42.65012181368022],[  -108.56689453125,  42.65012181368022],[  -108.56689453125,  43.50075243569041],[  -109.88525390624999,  43.50075243569041],[  -109.88525390624999,  42.65012181368022]]],\n",
    "    [[[  -117.61962890624999,  39.04478604850143],[  -116.65283203124999,  39.04478604850143],[  -116.65283203124999,  39.740986355883564],[  -117.61962890624999,  39.740986355883564],[  -117.61962890624999,  39.04478604850143]]],\n",
    "    [[[  -102.67822265625,  31.42866311735861],[  -101.71142578125,  31.42866311735861],[  -101.71142578125,  32.26855544621476],[  -102.67822265625,  32.26855544621476],[  -102.67822265625,  31.42866311735861]]],\n",
    "    [[[  -119.47631835937499,  36.03133177633187],[  -118.58642578124999,  36.03133177633187],[  -118.58642578124999,  36.55377524336089],[  -119.47631835937499,  36.55377524336089],[  -119.47631835937499,  36.03133177633187]]],\n",
    "    [[[  -116.224365234375,  33.091541548655215],[  -115.56518554687499,  33.091541548655215],[  -115.56518554687499,  33.568861182555565],[  -116.224365234375,  33.568861182555565],[  -116.224365234375,  33.091541548655215]]]\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    evalPolys = {\n",
    "      \"type\": \"FeatureCollection\",\n",
    "      \"features\": [\n",
    "        {\n",
    "          \"type\": \"Feature\",\n",
    "          \"properties\": {},\n",
    "          \"geometry\": {\n",
    "            \"type\": \"MultiPolygon\",\n",
    "            \"coordinates\":  [\n",
    "    [[[-122.13208008,   41.25126946],[-121.37402344,   41.25126946],[-121.37402344,   41.75892074],[-122.13208008,   41.75892074],[-122.13208008,   41.25126946]]],\n",
    "    [[[-121.15979004,   38.45555349],[-120.23144531,   38.45555349],[-120.23144531,   39.14764411],[-121.15979004,   39.14764411],[-121.15979004,   38.45555349]]],\n",
    "    [[[-111.80493164,   33.76787602],[-110.83813477,   33.76787602],[-110.83813477,   34.53827854],[-111.80493164,   34.53827854],[-111.80493164,   33.76787602]]],\n",
    "    [[[-106.125     ,   37.89280344],[-104.74072266,   37.89280344],[-104.74072266,   38.93638677],[-106.125     ,   38.93638677],[-106.125     ,   37.89280344]]],\n",
    "    [[[-119.08886719,   46.44083284],[-117.63867188,   46.44083284],[-117.63867188,   47.44466731],[-119.08886719,   47.44466731],[-119.08886719,   46.44083284]]],\n",
    "    [[[-99.84082031,  42.01129149],[-98.50048828,  42.01129149],[-98.50048828,  42.86452395],[-99.84082031,  42.86452395],[-99.84082031,  42.01129149]]],\n",
    "    [[[-96.6328125 ,  33.20415594],[-95.53417969,  33.20415594],[-95.53417969,  33.97949814],[-96.6328125 ,  33.97949814],[-96.6328125 ,  33.20415594]]],\n",
    "    [[[-93.44677734,  42.02780647],[-92.34814453,  42.02780647],[-92.34814453,  42.8808213 ],[-93.44677734,  42.8808213 ],[-93.44677734,  42.02780647]]],\n",
    "    [[[-89.27197266,  45.02667127],[-87.84375   ,  45.02667127],[-87.84375   ,  45.73034238],[-89.27197266,  45.73034238],[-89.27197266,  45.02667127]]],\n",
    "    [[[-68.79345703,  45.43427737],[-67.76074219,  45.43427737],[-67.76074219,  46.08670191],[-68.79345703,  46.08670191],[-68.79345703,  45.43427737]]],\n",
    "    [[[-80.68066406,  34.30970665],[-79.69189453,  34.30970665],[-79.69189453,  35.03899187],[-80.68066406,  35.03899187],[-80.68066406,  34.30970665]]],\n",
    "    [[[-116.86962891,   39.79478605],[-115.90283203,   39.79478605],[-115.90283203,   40.49098636],[-116.86962891,   40.49098636],[-116.86962891,   39.79478605]]]\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training polygons: 47\n",
      "Number of training polygons: 12\n"
     ]
    }
   ],
   "source": [
    "nTrain = len(trainPolys.get('features')[0].get('geometry').get('coordinates'))\n",
    "print('Number of training polygons:',  nTrain)\n",
    "\n",
    "if evalPolys:\n",
    "    nEval = len(evalPolys.get('features')[0].get('geometry').get('coordinates'))\n",
    "    print('Number of training polygons:',  nEval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display Polygons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x1133e6c88>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the URL format used for Earth Engine generated map tiles.\n",
    "EE_TILES = 'https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}'\n",
    "\n",
    "composite = ee_collection_specifics.Composite(collection)(startDate, stopDate)\n",
    "mapid = composite.getMapId(ee_collection_specifics.vizz_params_rgb(collection))\n",
    "\n",
    "tiles_url = EE_TILES.format(**mapid)\n",
    "\n",
    "map = folium.Map(location=[38., -100.], zoom_start=5)\n",
    "folium.TileLayer(\n",
    "tiles=tiles_url,\n",
    "attr='Google Earth Engine',\n",
    "overlay=True,\n",
    "name=str(ee_collection_specifics.ee_bands_rgb(collection))).add_to(map)\n",
    "    \n",
    "\n",
    "#  Convert the GeoJSONs to feature collections\n",
    "trainFeatures = ee.FeatureCollection(trainPolys.get('features'))\n",
    "if evalPolys:\n",
    "    evalFeatures = ee.FeatureCollection(evalPolys.get('features'))\n",
    "    \n",
    "polyImage = ee.Image(0).byte().paint(trainFeatures, 1)\n",
    "if evalPolys:\n",
    "    polyImage = ee.Image(0).byte().paint(trainFeatures, 1).paint(evalFeatures, 2)\n",
    "polyImage = polyImage.updateMask(polyImage)\n",
    "\n",
    "mapid = polyImage.getMapId({'min': 1, 'max': 2, 'palette': ['red', 'blue']})\n",
    "folium.TileLayer(\n",
    "    tiles=EE_TILES.format(**mapid),\n",
    "    attr='Google Earth Engine',\n",
    "    overlay=True,\n",
    "    name='training polygons',\n",
    "  ).add_to(map)\n",
    "\n",
    "map.add_child(folium.LayerControl())\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Data pre-processing\n",
    "\n",
    "We normalize the composite images to have values from 0 to 1.\n",
    "\n",
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inCollection = 'Landsat-8-Surface-Reflectance'\n",
    "outCollection = 'USDA-NASS-Cropland-Data-Layers'\n",
    "collections = [inCollection, outCollection]\n",
    "startDate = '2016-01-01'\n",
    "stopDate = '2016-12-31'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_values(image, collection, scale, polygons=None):\n",
    "    \n",
    "    normThreshold = ee_collection_specifics.ee_bands_normThreshold(collection)\n",
    "    \n",
    "    num = 2\n",
    "    lon = np.linspace(-180, 180, num)\n",
    "    lat = np.linspace(-90, 90, num)\n",
    "    \n",
    "    features = []\n",
    "    for i in range(len(lon)-1):\n",
    "        for j in range(len(lat)-1):\n",
    "            features.append(ee.Feature(ee.Geometry.Rectangle(lon[i], lat[j], lon[i+1], lat[j+1])))\n",
    "            \n",
    "    if not polygons:\n",
    "        polygons = ee.FeatureCollection(features)\n",
    "    \n",
    "    regReducer = {\n",
    "        'geometry': polygons,\n",
    "        'reducer': ee.Reducer.minMax(),\n",
    "        'maxPixels': 1e10,\n",
    "        'bestEffort': True,\n",
    "        'scale':scale,\n",
    "        'tileScale': 10\n",
    "        \n",
    "    }\n",
    "    \n",
    "    values = image.reduceRegion(**regReducer).getInfo()\n",
    "    print(values)\n",
    "    \n",
    "    # Avoid outliers by taking into account only the normThreshold% of the data points.\n",
    "    regReducer = {\n",
    "        'geometry': polygons, \n",
    "        'reducer': ee.Reducer.histogram(),\n",
    "        'maxPixels': 1e10,\n",
    "        'bestEffort': True,\n",
    "        'scale':scale,\n",
    "        'tileScale': 10\n",
    "        \n",
    "    }\n",
    "    \n",
    "    hist = image.reduceRegion(**regReducer).getInfo()\n",
    "\n",
    "    for band in list(normThreshold.keys()):\n",
    "        if normThreshold[band] != 100:\n",
    "            count = np.array(hist.get(band).get('histogram'))\n",
    "            x = np.array(hist.get(band).get('bucketMeans'))\n",
    "        \n",
    "            cumulative_per = np.cumsum(count/count.sum()*100)\n",
    "        \n",
    "            values[band+'_max'] = x[np.where(cumulative_per < normThreshold[band])][-1]\n",
    "        \n",
    "    return values\n",
    "\n",
    "def normalize_ee_images(image, collection, values):\n",
    "    \n",
    "    Bands = ee_collection_specifics.ee_bands(collection)\n",
    "       \n",
    "    # Normalize [0, 1] ee images\n",
    "    for i, band in enumerate(Bands):\n",
    "        if i == 0:\n",
    "            image_new = image.select(band).clamp(values[band+'_min'], values[band+'_max'])\\\n",
    "                                .subtract(values[band+'_min'])\\\n",
    "                                .divide(values[band+'_max']-values[band+'_min'])\n",
    "        else:\n",
    "            image_new = image_new.addBands(image.select(band).clamp(values[band+'_min'], values[band+'_max'])\\\n",
    "                                    .subtract(values[band+'_min'])\\\n",
    "                                    .divide(values[band+'_max']-values[band+'_min']))\n",
    "            \n",
    "    return image_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B10_max': 2995.0, 'B10_min': 2509.0, 'B11_max': 2978.0, 'B11_min': 2514.5, 'B1_max': 9901.0, 'B1_min': 3.0, 'B2_max': 9845.0, 'B2_min': 27.0, 'B3_max': 9743.0, 'B3_min': 27.0, 'B4_max': 9949.0, 'B4_min': 1.0, 'B5_max': 9549.0, 'B5_min': 1.0, 'B6_max': 7506.0, 'B6_min': 2.0, 'B7_max': 6017.0, 'B7_min': 1.0, 'ndvi_max': 0.932046332046332, 'ndvi_min': -0.8313253012048193, 'ndwi_max': 0.8611455492189437, 'ndwi_min': -0.9736842105263158}\n",
      "{'B10_max': 2995.0, 'B10_min': 2509.0, 'B11_max': 2978.0, 'B11_min': 2514.5, 'B1_max': 926.5338983050848, 'B1_min': 3.0, 'B2_max': 2589.553459119497, 'B2_min': 27.0, 'B3_max': 2593.205521472393, 'B3_min': 27.0, 'B4_max': 2400.3230769230768, 'B4_min': 1.0, 'B5_max': 9549.0, 'B5_min': 1.0, 'B6_max': 7506.0, 'B6_min': 2.0, 'B7_max': 6017.0, 'B7_min': 1.0, 'ndvi_max': 0.932046332046332, 'ndvi_min': -0.8313253012048193, 'ndwi_max': 0.8611455492189437, 'ndwi_min': -0.9736842105263158}\n",
      "CPU times: user 50.9 ms, sys: 34.5 ms, total: 85.5 ms\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "images = []\n",
    "for collection in collections:\n",
    "    # Create composite\n",
    "    image = ee_collection_specifics.Composite(collection)(startDate, stopDate)\n",
    "    \n",
    "    bands = ee_collection_specifics.ee_bands(collection)\n",
    "    image = image.select(bands)\n",
    "    \n",
    "    #Create composite\n",
    "    if ee_collection_specifics.normalize(collection):\n",
    "        # Get min man values for each band\n",
    "        values = min_max_values(image, collection, scale)\n",
    "        print(values)\n",
    "    \n",
    "        # Normalize images\n",
    "        image = normalize_ee_images(image, collection, values)\n",
    "    else:\n",
    "        values = {}\n",
    "        \n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display composite**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,<!DOCTYPE html>
<head>    
    <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
    <script>L_PREFER_CANVAS=false; L_NO_TOUCH=false; L_DISABLE_3D=false;</script>
    <script src="https://cdn.jsdelivr.net/npm/leaflet@1.4.0/dist/leaflet.js"></script>
    <script src="https://code.jquery.com/jquery-1.12.4.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.4.0/dist/leaflet.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css"/>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css"/>
    <link rel="stylesheet" href="https://rawcdn.githack.com/python-visualization/folium/master/folium/templates/leaflet.awesome.rotate.css"/>
    <style>html, body {width: 100%;height: 100%;margin: 0;padding: 0;}</style>
    <style>#map {position:absolute;top:0;bottom:0;right:0;left:0;}</style>
    
    <meta name="viewport" content="width=device-width,
        initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <style>#map_42974ea519a245d78015c08dc6f1e25c {
        position: relative;
        width: 100.0%;
        height: 100.0%;
        left: 0.0%;
        top: 0.0%;
        }
    </style>
</head>
<body>    
    
    <div class="folium-map" id="map_42974ea519a245d78015c08dc6f1e25c" ></div>
</body>
<script>    
    
    
        var bounds = null;
    

    var map_42974ea519a245d78015c08dc6f1e25c = L.map(
        'map_42974ea519a245d78015c08dc6f1e25c', {
        center: [38.0, -100.0],
        zoom: 5,
        maxBounds: bounds,
        layers: [],
        worldCopyJump: false,
        crs: L.CRS.EPSG3857,
        zoomControl: true,
        });


    
    var tile_layer_725bf22f95d44769a441f3b884337a17 = L.tileLayer(
        'https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png',
        {
        "attribution": null,
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_42974ea519a245d78015c08dc6f1e25c);
    var tile_layer_ab4fe03d69014816bb10349f646be7c5 = L.tileLayer(
        'https://earthengine.googleapis.com/map/d32e82104dfe578b41f45f5e39441b46/{z}/{x}/{y}?token=beb2fa63ed626a086ffba989873c3b52',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_42974ea519a245d78015c08dc6f1e25c);
    var tile_layer_06b3b985c2bb43b6ac2e786b9a570769 = L.tileLayer(
        'https://earthengine.googleapis.com/map/8c932b1336922a7a05a184f8ee37fc26/{z}/{x}/{y}?token=cb0d43ff01335b81ddb9c4e717cd6816',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_42974ea519a245d78015c08dc6f1e25c);
    var tile_layer_129145a3ee454b2f8c7a45c17b99b68a = L.tileLayer(
        'https://earthengine.googleapis.com/map/dd244fd1103821e32aa179458fde2e00/{z}/{x}/{y}?token=7286e34474a8b54ebeae1430e15d6e7a',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_42974ea519a245d78015c08dc6f1e25c);
    var tile_layer_2e504b63ffba42d68a666067e58b5037 = L.tileLayer(
        'https://earthengine.googleapis.com/map/c4fa80bc8319110048793f2a76aa1efb/{z}/{x}/{y}?token=f2cc8307d6eae6c6cfdb5982122e1449',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_42974ea519a245d78015c08dc6f1e25c);
    var tile_layer_5441164585b1448f81566350325308e8 = L.tileLayer(
        'https://earthengine.googleapis.com/map/af37000b7bce0dcaf6da1f409566bd6e/{z}/{x}/{y}?token=8c254dd0b7ac00f09829959efb2c10d5',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_42974ea519a245d78015c08dc6f1e25c);
    var tile_layer_077f212d26d84fdca69aa39340201173 = L.tileLayer(
        'https://earthengine.googleapis.com/map/1ce5341283bf411b4547ce839d801159/{z}/{x}/{y}?token=dfe62598023c9a1e2bf34b0a23a953d4',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_42974ea519a245d78015c08dc6f1e25c);
    var tile_layer_6d4049975df747f1841859ef75e8f39c = L.tileLayer(
        'https://earthengine.googleapis.com/map/d9a0d9ddb451a4c511cf89002add783f/{z}/{x}/{y}?token=c5104930389e7fa5e7838f58c31a4763',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_42974ea519a245d78015c08dc6f1e25c);
    var tile_layer_dff81b69090c426db79582ad736389cb = L.tileLayer(
        'https://earthengine.googleapis.com/map/c9fc5f763aa53c21fe36f45ffe91c5c0/{z}/{x}/{y}?token=2eff773e5ffcaf1aeb6decf3d0040885',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_42974ea519a245d78015c08dc6f1e25c);
    var tile_layer_b924605aeb8d48789754579923f1ba2d = L.tileLayer(
        'https://earthengine.googleapis.com/map/d19ad73d8b36002c151476526733b303/{z}/{x}/{y}?token=5443bfe2d65009c50d7250e9219c59fb',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_42974ea519a245d78015c08dc6f1e25c);
    var tile_layer_ac6e2c300cdb43e0871ae97ff35f4381 = L.tileLayer(
        'https://earthengine.googleapis.com/map/f4030c36fd7eaf8015db465fc5b08975/{z}/{x}/{y}?token=e0383c00a42103133861b563e1ac3e31',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_42974ea519a245d78015c08dc6f1e25c);
    var tile_layer_b50c6257b50442fd9516c21b3cbb4904 = L.tileLayer(
        'https://earthengine.googleapis.com/map/8bdc174b410c3a598758340090dd3c1b/{z}/{x}/{y}?token=36ff3e2b73be623221f507c9c6381ca9',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_42974ea519a245d78015c08dc6f1e25c);
    var tile_layer_69213e288bfe4aaeb4135055cc9be1ab = L.tileLayer(
        'https://earthengine.googleapis.com/map/4cd85933da80d723ac2cd9301a715767/{z}/{x}/{y}?token=d96b09fc73ff7bba92bb87ab59d72ed8',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_42974ea519a245d78015c08dc6f1e25c);
    var tile_layer_431f408a083a47198080228b3c0865e4 = L.tileLayer(
        'https://earthengine.googleapis.com/map/37417cc75249e2df9deeb01f970d00d5/{z}/{x}/{y}?token=3f414ee707fb76475776f74b42afe343',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_42974ea519a245d78015c08dc6f1e25c);
    var tile_layer_d3ca33f5a31f43a18da0d862928d6058 = L.tileLayer(
        'https://earthengine.googleapis.com/map/ddb826b9ba3b7ab4e6d7f7052cdc22c7/{z}/{x}/{y}?token=760744e7fb08aaa0e659cc1bca324d1e',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_42974ea519a245d78015c08dc6f1e25c);
    var tile_layer_5c83809c716d456990757435072bd2a6 = L.tileLayer(
        'https://earthengine.googleapis.com/map/6a826949bff2075f84a2f3ab4a71bc93/{z}/{x}/{y}?token=de1fe1e3bee18b6eff979298bacbd466',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_42974ea519a245d78015c08dc6f1e25c);
    
            var layer_control_71bea900d7ce4327be4109aa3e4b2a3b = {
                base_layers : { "openstreetmap" : tile_layer_725bf22f95d44769a441f3b884337a17, },
                overlays : { "['B4', 'B3', 'B2']" : tile_layer_ab4fe03d69014816bb10349f646be7c5,"['B1']" : tile_layer_06b3b985c2bb43b6ac2e786b9a570769,"['B5']" : tile_layer_129145a3ee454b2f8c7a45c17b99b68a,"['B6']" : tile_layer_2e504b63ffba42d68a666067e58b5037,"['B7']" : tile_layer_5441164585b1448f81566350325308e8,"['B10']" : tile_layer_077f212d26d84fdca69aa39340201173,"['B11']" : tile_layer_6d4049975df747f1841859ef75e8f39c,"['ndvi']" : tile_layer_dff81b69090c426db79582ad736389cb,"['ndwi']" : tile_layer_b924605aeb8d48789754579923f1ba2d,"['landcover']" : tile_layer_ac6e2c300cdb43e0871ae97ff35f4381,"['cropland']" : tile_layer_b50c6257b50442fd9516c21b3cbb4904,"['land']" : tile_layer_69213e288bfe4aaeb4135055cc9be1ab,"['water']" : tile_layer_431f408a083a47198080228b3c0865e4,"['urban']" : tile_layer_d3ca33f5a31f43a18da0d862928d6058,"training polygons" : tile_layer_5c83809c716d456990757435072bd2a6, }
                };
            L.control.layers(
                layer_control_71bea900d7ce4327be4109aa3e4b2a3b.base_layers,
                layer_control_71bea900d7ce4327be4109aa3e4b2a3b.overlays,
                {position: 'topright',
                 collapsed: true,
                 autoZIndex: true
                }).addTo(map_42974ea519a245d78015c08dc6f1e25c);
            
        
</script>\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x1132e6390>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the URL format used for Earth Engine generated map tiles.\n",
    "EE_TILES = 'https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}'\n",
    "map = folium.Map(location=[38., -100.], zoom_start=5)\n",
    "for n, collection in enumerate(collections):\n",
    "    for params in ee_collection_specifics.vizz_params(collection):\n",
    "        mapid = images[n].getMapId(params)\n",
    "        folium.TileLayer(\n",
    "        tiles=EE_TILES.format(**mapid),\n",
    "        attr='Google Earth Engine',\n",
    "        overlay=True,\n",
    "        name=str(params['bands']),\n",
    "      ).add_to(map)\n",
    "        \n",
    "#  Convert the GeoJSONs to feature collections\n",
    "trainFeatures = ee.FeatureCollection(trainPolys.get('features'))\n",
    "if evalPolys:\n",
    "    evalFeatures = ee.FeatureCollection(evalPolys.get('features'))\n",
    "    \n",
    "polyImage = ee.Image(0).byte().paint(trainFeatures, 1)\n",
    "if evalPolys:\n",
    "    polyImage = ee.Image(0).byte().paint(trainFeatures, 1).paint(evalFeatures, 2)\n",
    "polyImage = polyImage.updateMask(polyImage)\n",
    "\n",
    "mapid = polyImage.getMapId({'min': 1, 'max': 2, 'palette': ['red', 'blue']})\n",
    "folium.TileLayer(\n",
    "    tiles=EE_TILES.format(**mapid),\n",
    "    attr='Google Earth Engine',\n",
    "    overlay=True,\n",
    "    name='training polygons',\n",
    "  ).add_to(map)\n",
    "\n",
    "map.add_child(folium.LayerControl())\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Create TFRecords for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export images\n",
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inCollection = 'Landsat8_SR'\n",
    "outCollection = 'NationalLandCoverDatabase'#'CroplandDataLayers'\n",
    "inBands = ['B1','B2','B3','B4','B5','B6','B7','ndvi','ndwi']\n",
    "outBands = ['impervious']#['cropland', 'land', 'water', 'urban']\n",
    "startDate = '2016-01-01'\n",
    "stopDate = '2016-12-31'\n",
    "scale = 30 #scale in meters\n",
    "sampleSize = 1000 # Total sample size in each polygon.\n",
    "datasetName = 'Landsat8_Impervious'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An array of images**\n",
    "\n",
    "We have to stack the 2D images (input and output images of the Neural Network) to create a single image from which samples can be taken. Convert the image into an array image in which each pixel stores 256x256 patches of pixels for each band. This is a key step that bears emphasis: to export training patches, convert a multi-band image to [an array image](https://developers.google.com/earth-engine/arrays_array_images#array-images) using [neighborhoodToArray()](https://developers.google.com/earth-engine/api_docs#eeimageneighborhoodtoarray), then sample the image at points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_into_array(url, collections, bands, kernelSize, startDate, stopDate, scale):\n",
    "\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    \n",
    "    for i, collection in enumerate(collections):\n",
    "        payload =   {\n",
    "            \"collection\": collection,\n",
    "            \"start\": startDate,\n",
    "            \"end\": stopDate,\n",
    "            \"scale\": scale\n",
    "        }\n",
    "        \n",
    "        output = requests.post(url, data=json.dumps(payload), headers=headers)\n",
    "        \n",
    "        if i == 0:\n",
    "            image = ee.deserializer.fromJSON(output.json()['composite']).select(bands[i])\n",
    "        else:\n",
    "            featureStack = ee.Image.cat([image,\\\n",
    "                                         ee.deserializer.fromJSON(output.json()['composite']).select(bands[i])\\\n",
    "                                        ]).float()\n",
    "            \n",
    "    list = ee.List.repeat(1, kernelSize)\n",
    "    lists = ee.List.repeat(list, kernelSize)\n",
    "    kernel = ee.Kernel.fixed(kernelSize, kernelSize, lists)\n",
    "    \n",
    "    arrays = featureStack.neighborhoodToArray(kernel)\n",
    "    \n",
    "    return arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = f'https://us-central1-skydipper-196010.cloudfunctions.net/ee_pre_processing'\n",
    "\n",
    "collections = [inCollection, outCollection]\n",
    "bands = [inBands, outBands]\n",
    "kernelSize = 256\n",
    "\n",
    "arrays = image_into_array(url, collections, bands, kernelSize, startDate, stopDate, scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export TFRecords**\n",
    "\n",
    "The mapped data look reasonable so take a sample from each polygon and merge the results into a single export. The key step is sampling the array image at points, to get all the pixels in a 256x256 neighborhood at each point. It's worth noting that to build the training and testing data for the FCNN, you export a single TFRecord file that contains patches of pixel values in each record. You do NOT need to export each training/testing patch to a different image. Since each record potentially contains a lot of data (especially with big patches or many input bands), some manual sharding of the computation is necessary to avoid the computed value too large error. Specifically, the following code takes multiple (smaller) samples within each geometry, merging the results to get a single export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_TFRecords_images(arrays, scale, nShards, sampleSize, features, polysLists, baseNames, bucket, folder, selectors):\n",
    "    # Export all the training/evaluation data (in many pieces), with one task per geometry.\n",
    "    filePaths = []\n",
    "    for i, feature in enumerate(features):\n",
    "        for g in range(feature.size().getInfo()):\n",
    "            geomSample = ee.FeatureCollection([])\n",
    "            for j in range(nShards):\n",
    "                sample = arrays.sample(\n",
    "                    region = ee.Feature(polysLists[i].get(g)).geometry(), \n",
    "                    scale = scale, \n",
    "                    numPixels = sampleSize / nShards, # Size of the shard.\n",
    "                    seed = j,\n",
    "                    tileScale = 8\n",
    "                )\n",
    "                geomSample = geomSample.merge(sample)\n",
    "                \n",
    "            desc = baseNames[i] + '_g' + str(g)\n",
    "            \n",
    "            filePaths.append(bucket+ '/' + folder + '/' + desc)\n",
    "            \n",
    "            task = ee.batch.Export.table.toCloudStorage(\n",
    "                collection = geomSample,\n",
    "                description = desc, \n",
    "                bucket = bucket, \n",
    "                fileNamePrefix = folder + '/' + desc,\n",
    "                fileFormat = 'TFRecord',\n",
    "                selectors = selectors\n",
    "            )\n",
    "            task.start()\n",
    "            \n",
    "    return filePaths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeoJSONs_to_FeatureCollections(multipolygon):\n",
    "    # Make a list of Features\n",
    "    features = []\n",
    "    for i in range(len(multipolygon.get('features')[0].get('geometry').get('coordinates'))):\n",
    "        features.append(\n",
    "            ee.Feature(\n",
    "                ee.Geometry.Polygon(\n",
    "                    multipolygon.get('features')[0].get('geometry').get('coordinates')[i]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    # Create a FeatureCollection from the list and print it.\n",
    "    return ee.FeatureCollection(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the GeoJSONs to feature collections\n",
    "trainFeatures = GeoJSONs_to_FeatureCollections(trainPolys)\n",
    "evalFeatures = GeoJSONs_to_FeatureCollections(evalPolys)\n",
    "\n",
    "# Convert the feature collections to lists for iteration.\n",
    "trainPolysList = trainFeatures.toList(trainFeatures.size())\n",
    "evalPolysList = evalFeatures.toList(evalFeatures.size())\n",
    "\n",
    "# These numbers determined experimentally.\n",
    "nShards  = int(sampleSize/20)#100 # Number of shards in each polygon.\n",
    "\n",
    "features = [trainFeatures, evalFeatures]\n",
    "polysLists = [trainPolysList, evalPolysList]\n",
    "baseNames = ['training_patches', 'eval_patches']\n",
    "bucket = 'skydipper_materials'\n",
    "folder = 'cnn-models/'+datasetName+'/data'\n",
    "selectors = inBands + outBands\n",
    "\n",
    "# Export all the training/evaluation data (in many pieces), with one task per geometry.\n",
    "#filePaths = export_TFRecords_images(arrays, scale, nShards, sampleSize, features, polysLists, baseNames, bucket, folder, selectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Inspect data\n",
    "Load the data exported from Earth Engine into a tf.data.Dataset. \n",
    "\n",
    "**Helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow setup.\n",
    "import tensorflow as tf\n",
    "\n",
    "if tf.__version__ == '1.15.0':\n",
    "    tf.enable_eager_execution()\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function(proto):\n",
    "    \"\"\"The parsing function.\n",
    "    Read a serialized example into the structure defined by FEATURES_DICT.\n",
    "    Args:\n",
    "      example_proto: a serialized Example.\n",
    "    Returns: \n",
    "      A dictionary of tensors, keyed by feature name.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define your tfrecord \n",
    "    features = inBands + outBands\n",
    "    \n",
    "    # Specify the size and shape of patches expected by the model.\n",
    "    kernel_shape = [kernel_size, kernel_size]\n",
    "    columns = [\n",
    "      tf.io.FixedLenFeature(shape=kernel_shape, dtype=tf.float32) for k in features\n",
    "    ]\n",
    "    features_dict = dict(zip(features, columns))\n",
    "    \n",
    "    # Load one example\n",
    "    parsed_features = tf.io.parse_single_example(proto, features_dict)\n",
    "\n",
    "    # Convert a dictionary of tensors to a tuple of (inputs, outputs)\n",
    "    inputsList = [parsed_features.get(key) for key in features]\n",
    "    stacked = tf.stack(inputsList, axis=0)\n",
    "    \n",
    "    # Convert the tensors into a stack in HWC shape\n",
    "    stacked = tf.transpose(stacked, [1, 0])\n",
    "    \n",
    "    return stacked[:,:,:len(inBands)], stacked[:,:,len(inBands):]\n",
    "\n",
    "def get_dataset(glob, inBands, outBands, kernel_size, buffer_size, batch_size):\n",
    "    \"\"\"Get the preprocessed training dataset\n",
    "    Returns: \n",
    "    A tf.data.Dataset of training data.\n",
    "    \"\"\"\n",
    "    glob = tf.compat.v1.io.gfile.glob(glob)\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=5)\n",
    "    \n",
    "    dataset = dataset.shuffle(buffer_size).batch(batch_size).repeat()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetName = 'Landsat8_Impervious'#'Landsat8_Cropland'\n",
    "baseNames = ['training_patches', 'eval_patches']\n",
    "inBands = ['B1','B2','B3','B4','B5','B6','B7','ndvi','ndwi']\n",
    "outBands = ['impervious']#['cropland', 'land', 'water', 'urban']\n",
    "        \n",
    "bucket = env.bucket_name\n",
    "folder = 'cnn-models/'+datasetName+'/data1'\n",
    "kernel_size = 256\n",
    "buffer_size = 100\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob = 'gs://' + bucket + '/' + folder + '/' + baseNames[0] + '_g0'+ '*'\n",
    "dataset = get_dataset(glob, inBands, outBands, kernel_size, buffer_size, batch_size)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the first record**\n",
    "\n",
    "Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arr = iter(dataset.take(1)).next()\n",
    "input_arr = training_arr[0].numpy()\n",
    "print(input_arr.shape)\n",
    "output_arr = training_arr[1].numpy()\n",
    "print(output_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And display the channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_channels(data, nChannels, titles = False):\n",
    "    if nChannels == 1:\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.imshow(data[:,:,0])\n",
    "        if titles:\n",
    "            plt.title(titles[0])\n",
    "    else:\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=nChannels, figsize=(5*nChannels,5))\n",
    "        for i in range(nChannels):\n",
    "            ax = axs[i]\n",
    "            ax.imshow(data[:,:,i])\n",
    "            if titles:\n",
    "                ax.set_title(titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_channels(input_arr[2,:,:,:], input_arr.shape[3], titles=inBands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_channels(output_arr[2,:,:,:], output_arr.shape[3], titles=outBands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Training the model in AI Platform\n",
    "### Training code package setup\n",
    "\n",
    "It's necessary to create a Python package to hold the training code.  Here we're going to get started with that by creating a folder for the package and adding an empty `__init__.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = 'AI_Platform/cnn_trainer'\n",
    "PACKAGE_FOLDER = '/trainer'\n",
    "\n",
    "!rm -r {ROOT_PATH}\n",
    "!mkdir {ROOT_PATH}\n",
    "!mkdir {ROOT_PATH+PACKAGE_FOLDER}\n",
    "!touch {ROOT_PATH+PACKAGE_FOLDER}/__init__.py\n",
    "!ls -l {ROOT_PATH+PACKAGE_FOLDER}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Files**\n",
    "\n",
    "`env.py` file into the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp env.py {ROOT_PATH+PACKAGE_FOLDER}/env.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables**\n",
    "\n",
    "These variables need to be stored in a place where other code can access them.  There are a variety of ways of accomplishing that, but here we'll use the `%%writefile` command to write the contents of the code cell to a file called `config.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {ROOT_PATH+PACKAGE_FOLDER}/config.py\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from . import env\n",
    "\n",
    "# Define your Google Cloud Storage bucket\n",
    "bucket = env.bucket_name\n",
    "\n",
    "# Specify names of output locations in Cloud Storage.\n",
    "dataset_name = 'Landsat8_Impervious'#'Landsat8_Cropland'\n",
    "job_dir = 'gs://' + bucket + '/' + 'cnn-models/'+ dataset_name +'/trainer'\n",
    "model_dir = job_dir + '/model'\n",
    "logs_dir = job_dir + '/logs'\n",
    "\n",
    "# Pre-computed training and eval data.\n",
    "base_names = ['training_patches', 'eval_patches']\n",
    "folder = 'cnn-models/'+dataset_name+'/data'\n",
    "\n",
    "# Specify inputs/outputs to the model\n",
    "in_bands = ['B1','B2','B3','B4','B5','B6','B7','ndvi','ndwi']\n",
    "out_bands = ['impervious']#['cropland', 'land', 'water', 'urban']\n",
    "\n",
    "# Specify the size and shape of patches expected by the model.\n",
    "kernel_size = 256\n",
    "\n",
    "# Sizes of the training and evaluation datasets.\n",
    "train_size = 1000*36\n",
    "eval_size = 1000*11\n",
    "\n",
    "# Specify model training parameters.\n",
    "model_type = 'regression'\n",
    "model_architecture = 'unet'\n",
    "output_activation = 'sigmoid'\n",
    "batch_size = 16\n",
    "epochs = 1\n",
    "shuffle_size = 2000\n",
    "learning_rate = 1e-3\n",
    "optimizer = tf.keras.optimizers.SGD(lr=learning_rate)\n",
    "loss = 'mse'\n",
    "metrics = ['RootMeanSquaredError']#['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training/evaluation data**\n",
    "\n",
    "The following is code to load training/evaluation data.  Write this into `util.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {ROOT_PATH+PACKAGE_FOLDER}/util.py\n",
    "\"\"\"Utilities to download and preprocess the data.\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from . import config\n",
    "\n",
    "def parse_function(proto):\n",
    "    \"\"\"The parsing function.\n",
    "    Read a serialized example into the structure defined by features_dict.\n",
    "    Args:\n",
    "      example_proto: a serialized Example.\n",
    "    Returns: \n",
    "      A dictionary of tensors, keyed by feature name.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define your tfrecord \n",
    "    features = config.in_bands + config.out_bands\n",
    "    \n",
    "    # Specify the size and shape of patches expected by the model.\n",
    "    kernel_shape = [config.kernel_size, config.kernel_size]\n",
    "    columns = [\n",
    "      tf.io.FixedLenFeature(shape=kernel_shape, dtype=tf.float32) for k in features\n",
    "    ]\n",
    "    features_dict = dict(zip(features, columns))\n",
    "    \n",
    "    # Load one example\n",
    "    parsed_features = tf.io.parse_single_example(proto, features_dict)\n",
    "\n",
    "    # Convert a dictionary of tensors to a tuple of (inputs, outputs)\n",
    "    inputs_list = [parsed_features.get(key) for key in features]\n",
    "    stacked = tf.stack(inputs_list, axis=0)\n",
    "    \n",
    "    # Convert the tensors into a stack in HWC shape\n",
    "    stacked = tf.transpose(stacked, [1, 2, 0])\n",
    "    \n",
    "    return stacked[:,:,:len(config.in_bands)], stacked[:,:,len(config.in_bands):]\n",
    "\n",
    "def get_dataset(glob):\n",
    "    \"\"\"Get the preprocessed training dataset\n",
    "    Returns: \n",
    "    A tf.data.Dataset of training data.\n",
    "    \"\"\"\n",
    "    glob = tf.compat.v1.io.gfile.glob(glob)\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=5)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_training_dataset():\n",
    "    \"\"\"Get the preprocessed training dataset\n",
    "    Returns: \n",
    "    A tf.data.Dataset of training data.\n",
    "    \"\"\"\n",
    "    glob = 'gs://' + config.bucket + '/' + config.folder + '/' + config.base_names[0] + '*'\n",
    "    dataset = get_dataset(glob)\n",
    "    dataset = dataset.shuffle(config.shuffle_size).batch(config.batch_size).repeat()\n",
    "    return dataset\n",
    "\n",
    "def get_evaluation_dataset():\n",
    "    \"\"\"Get the preprocessed evaluation dataset\n",
    "    Returns: \n",
    "      A tf.data.Dataset of evaluation data.\n",
    "    \"\"\"\n",
    "    glob = 'gs://' + config.bucket + '/' + config.folder + '/' + config.base_names[1] + '*'\n",
    "    dataset = get_dataset(glob)\n",
    "    dataset = dataset.batch(1).repeat()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that `util.py` is functioning as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI_Platform.cnn_trainer.trainer import config\n",
    "from AI_Platform.cnn_trainer.trainer import util\n",
    "\n",
    "training_dataset = util.get_training_dataset()\n",
    "training_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model**\n",
    "\n",
    "We rewrite the desired model (previously specified in `config.py`) into `model.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI_Platform.cnn_trainer.trainer import config\n",
    "!cp ../models/{config.model_type}/{config.model_architecture+'.py'} {ROOT_PATH+PACKAGE_FOLDER}/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that `model.py` is functioning as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI_Platform.cnn_trainer.trainer import config\n",
    "from AI_Platform.cnn_trainer.trainer import model\n",
    "\n",
    "model = model.create_keras_model(inputShape = (None, None, len(config.in_bands)), nClasses = len(config.out_bands))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training task**\n",
    "\n",
    "The following will create `task.py`, which will get the training and evaluation data, train the model and save it when it's done in a Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {ROOT_PATH+PACKAGE_FOLDER}/task.py\n",
    "\"\"\"Trains a Keras model\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from . import config\n",
    "from . import util\n",
    "from . import model\n",
    "          \n",
    "def train_and_evaluate():\n",
    "    \"\"\"Trains and evaluates the Keras model.\n",
    "\n",
    "    Uses the Keras model defined in model.py and trains on data loaded and\n",
    "    preprocessed in util.py. Saves the trained model in TensorFlow SavedModel\n",
    "    format to the path defined in part by the --job-dir argument.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the Keras Model\n",
    "    if not config.output_activation:\n",
    "        keras_model = model.create_keras_model(inputShape = (None, None, len(config.in_bands)), nClasses = len(config.out_bands))\n",
    "    else:\n",
    "        keras_model = model.create_keras_model(inputShape = (None, None, len(config.in_bands)), nClasses = len(config.out_bands), output_activation = config.output_activation)\n",
    "\n",
    "    # Compile Keras model\n",
    "    keras_model.compile(loss=config.loss, optimizer=config.optimizer, metrics=config.metrics)\n",
    "\n",
    "\n",
    "    # Pass a tfrecord\n",
    "    training_dataset = util.get_training_dataset()\n",
    "    evaluation_dataset = util.get_evaluation_dataset()\n",
    "\n",
    "    # Setup TensorBoard callback.\n",
    "    tensorboard_cb = tf.keras.callbacks.TensorBoard(config.logs_dir)\n",
    "\n",
    "    # Train model\n",
    "    keras_model.fit(\n",
    "        x=training_dataset,\n",
    "        steps_per_epoch=int(config.train_size / config.batch_size),\n",
    "        epochs=config.epochs,\n",
    "        validation_data=evaluation_dataset,\n",
    "        validation_steps=int(config.eval_size / config.batch_size),\n",
    "        verbose=1,\n",
    "        callbacks=[tensorboard_cb])\n",
    "\n",
    "    tf.contrib.saved_model.save_keras_model(keras_model, os.path.join(config.model_dir, str(int(time.time()))))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.logging.set_verbosity('INFO')\n",
    "    train_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using GPUs**\n",
    "\n",
    "AI Platform lets you run any TensorFlow training application on a GPU-enabled machine. Learn more about [using GPUs for training models in the cloud](https://cloud.google.com/ml-engine/docs/tensorflow/using-gpus#submit-job).\n",
    "We define a `config.yaml` file that describes the GPU options we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {ROOT_PATH}/config.yaml\n",
    "\n",
    "trainingInput:\n",
    "    scaleTier: CUSTOM\n",
    "    # A single NVIDIA Tesla V100 GPU\n",
    "    masterType: large_model_v100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the package to AI Platform for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# INSERT YOUR PROJECT HERE!\n",
    "PROJECT_ID = env.project_id\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "JOB_NAME = 'job_v' + str(int(time.time()))\n",
    "TRAINER_PACKAGE_PATH = 'AI_Platform/cnn_trainer/trainer/'\n",
    "MAIN_TRAINER_MODULE = 'trainer.task'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up your GCP project**\n",
    "\n",
    "Enter your project ID in the cell below. Then run the cell to make sure the Cloud SDK uses the right project for all the commands in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authenticate your GCP account**\n",
    "\n",
    "Enter the path to your service account key as the\n",
    "`GOOGLE_APPLICATION_CREDENTIALS` variable in the cell below and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env GOOGLE_APPLICATION_CREDENTIALS 'privatekey.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submit a training job to AI Platform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud ai-platform jobs submit training {JOB_NAME} \\\n",
    "    --job-dir {config.job_dir} \\\n",
    "    --package-path {TRAINER_PACKAGE_PATH} \\\n",
    "    --module-name {MAIN_TRAINER_MODULE} \\\n",
    "    --region {REGION} \\\n",
    "    --config {ROOT_PATH}/config.yaml \\\n",
    "    --runtime-version 1.14 \\\n",
    "    --python-version 3.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Monitor the training job**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = !gcloud ai-platform jobs describe {JOB_NAME} --project {PROJECT_ID}\n",
    "state = desc.grep('state:')[0].split(':')[1].strip()\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Prepare the model for making predictions in Earth Engine\n",
    "\n",
    "Before we can use the model in Earth Engine, it needs to be hosted by AI Platform.  But before we can host the model on AI Platform we need to *EEify* (a new word!) it.  The EEification process merely appends some extra operations to the input and outputs of the model in order to accomdate the interchange format between pixels from Earth Engine (float32) and inputs to AI Platform (base64).  (See [this doc](https://cloud.google.com/ml-engine/docs/online-predict#binary_data_in_prediction_input) for details.)  \n",
    "\n",
    "**`earthengine model prepare`**\n",
    "\n",
    "The EEification process is handled for you using the Earth Engine command `earthengine model prepare`.  To use that command, we need to specify the input and output model directories and the name of the input and output nodes in the TensorFlow computation graph.  We can do all that programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inBands = ['B1','B2','B3','B4','B5','B6','B7','ndvi','ndwi']\n",
    "outBands = ['impervious']#['cropland', 'land', 'water', 'urban']\n",
    "\n",
    "# Specify names of input locations in Cloud Storage.\n",
    "dataset_name = 'Landsat8_Impervious'#'Landsat8_Cropland'\n",
    "job_dir = 'gs://' + env.bucket_name + '/' + 'cnn-models/' + dataset_name + '/trainer'\n",
    "model_dir = job_dir + '/model'\n",
    "PROJECT_ID = env.project_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the directory with the latest timestamp, in case you've trained multiple times\n",
    "exported_model_dirs = ! gsutil ls {model_dir}\n",
    "saved_model_path = exported_model_dirs[-1]\n",
    "\n",
    "folder_name = saved_model_path.split('/')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import saved_model_utils\n",
    "\n",
    "meta_graph_def = saved_model_utils.get_meta_graph_def(saved_model_path, 'serve')\n",
    "inputs = meta_graph_def.signature_def['serving_default'].inputs\n",
    "outputs = meta_graph_def.signature_def['serving_default'].outputs\n",
    "\n",
    "# Just get the first thing(s) from the serving signature def.  i.e. this\n",
    "# model only has a single input and a single output.\n",
    "input_name = None\n",
    "for k,v in inputs.items():\n",
    "    input_name = v.name\n",
    "    break\n",
    "\n",
    "output_name = None\n",
    "for k,v in outputs.items():\n",
    "    output_name = v.name\n",
    "    break\n",
    "\n",
    "# Make a dictionary that maps Earth Engine outputs and inputs to \n",
    "# AI Platform inputs and outputs, respectively.\n",
    "import json\n",
    "input_dict = \"'\" + json.dumps({input_name: \"array\"}) + \"'\"\n",
    "output_dict = \"'\" + json.dumps({output_name: \"prediction\"}) + \"'\"\n",
    "\n",
    "# Put the EEified model next to the trained model directory.\n",
    "EEIFIED_DIR = job_dir + '/eeified/' + folder_name\n",
    "\n",
    "# You need to set the project before using the model prepare command.\n",
    "!earthengine set_project {PROJECT_ID}\n",
    "!earthengine model prepare --source_dir {saved_model_path} --dest_dir {EEIFIED_DIR} --input {input_dict} --output {output_dict}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deployed the model to AI Platform**\n",
    "\n",
    "Before it's possible to get predictions from the trained and EEified model, it needs to be deployed on AI Platform.  The first step is to create the model.  The second step is to create a version.  See [this guide](https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models) for details.  Note that models and versions can be monitored from the [AI Platform models page](http://console.cloud.google.com/ai-platform/models) of the Cloud Console. \n",
    "\n",
    "To ensure that the model is ready for predictions without having to warm up nodes, you can use a configuration yaml file to set the scaling type of this version to autoScaling, and, set a minimum number of nodes for the version. This will ensure there are always nodes on stand-by, however, you will be charged as long as they are running. For this example, we'll set the minNodes to 10. That means that at a minimum, 10 nodes are always up and running and waiting for predictions. The number of nodes will also scale up automatically if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile config.yaml\n",
    "autoScaling:\n",
    "    minNodes: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from AI_Platform.cnn_trainer.trainer import config\n",
    "\n",
    "REGION = \"us-central1\"\n",
    "MODEL_NAME = config.model_architecture+'_'+dataset_name\n",
    "VERSION_NAME = 'v' + folder_name\n",
    "print('Creating version: ' + VERSION_NAME)\n",
    "\n",
    "!gcloud ai-platform models create {MODEL_NAME} \n",
    "!gcloud ai-platform versions create {VERSION_NAME} \\\n",
    "  --model {MODEL_NAME} \\\n",
    "  --origin {EEIFIED_DIR} \\\n",
    "  --runtime-version=1.14 \\\n",
    "  --framework \"TENSORFLOW\" \\\n",
    "  --python-version=3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Predict in Earth Engine\n",
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI_Platform.cnn_trainer.trainer import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inCollection = 'Landsat8_SR'\n",
    "inBands = ['B1','B2','B3','B4','B5','B6','B7'] #['B1','B2','B3','B4','B5','B6','B7','ndvi','ndwi']\n",
    "outBands = ['impervious']#['cropland', 'land', 'water', 'urban']\n",
    "startDate = '2016-01-01'\n",
    "stopDate = '2016-12-31'\n",
    "scale = 30 #scale in meters\n",
    "\n",
    "# Model variables\n",
    "PROJECT_ID = env.project_id\n",
    "MODEL_NAME = 'deepvel_Landsat8_Impervious' #config.model_architecture+'_'+dataset_name\n",
    "VERSION_NAME = 'v1578585185'\n",
    "model_type = config.model_type\n",
    "\n",
    "# polygon where we want to display de predictions\n",
    "geometry = {\n",
    "  \"type\": \"FeatureCollection\",\n",
    "  \"features\": [\n",
    "    {\n",
    "      \"type\": \"Feature\",\n",
    "      \"properties\": {},\n",
    "      \"geometry\": {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [\n",
    "          [\n",
    "            [\n",
    "              -3.9990234375,\n",
    "              40.17887331434696\n",
    "            ],\n",
    "            [\n",
    "              -3.3343505859375,\n",
    "              40.17887331434696\n",
    "            ],\n",
    "            [\n",
    "              -3.3343505859375,\n",
    "              40.57849862511043\n",
    "            ],\n",
    "            [\n",
    "              -3.9990234375,\n",
    "              40.57849862511043\n",
    "            ],\n",
    "            [\n",
    "              -3.9990234375,\n",
    "              40.17887331434696\n",
    "            ]\n",
    "          ]\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ee.Model.fromAiPlatformPredictor`**\n",
    "\n",
    "There is now a trained model, prepared for serving to Earth Engine, hosted and versioned on AI Platform.  \n",
    "We can now connect Earth Engine directly to the trained model for inference.  You do that with the `ee.Model.fromAiPlatformPredictor` command.\n",
    "For this command to work, we need to know a lot about the model.  To connect to the model, you need to know the name and version.\n",
    "\n",
    "**Inputs**\n",
    "\n",
    "You need to be able to recreate the imagery on which it was trained in order to perform inference.  Specifically, you need to create an array-valued input from the scaled data and use that for input.  (Recall that the new input node is named `array`, which is convenient because the array image has one band, named `array` by default.)  The inputs will be provided as 144x144 patches (`inputTileSize`), at 30-meter resolution (`proj`), but 8 pixels will be thrown out (`inputOverlapSize`) to minimize boundary effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "payload =   {\n",
    "    \"collection\": inCollection,\n",
    "    \"start\": startDate,\n",
    "    \"end\": stopDate,\n",
    "    \"scale\": scale\n",
    "}\n",
    "\n",
    "url = f'https://us-central1-skydipper-196010.cloudfunctions.net/ee_pre_processing'\n",
    "\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "output_pre_processing = requests.post(url, data=json.dumps(payload), headers=headers)\n",
    "output_pre_processing.json()\n",
    "\n",
    "image = ee.deserializer.fromJSON(output_pre_processing.json()['composite'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select bands and convert them into float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.select(inBands).float()\n",
    "image.getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outputs**\n",
    "\n",
    "The output (which you also need to know)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model and use it for prediction.\n",
    "model = ee.Model.fromAiPlatformPredictor(\n",
    "    projectName = PROJECT_ID,\n",
    "    modelName = MODEL_NAME,\n",
    "    version = VERSION_NAME,\n",
    "    inputTileSize = [144, 144],\n",
    "    inputOverlapSize = [8, 8],\n",
    "    proj = ee.Projection('EPSG:4326').atScale(scale),\n",
    "    fixInputProj = True,\n",
    "    outputBands = {'prediction': {\n",
    "        'type': ee.PixelType.float(),\n",
    "        'dimensions': 1,\n",
    "      }                  \n",
    "    }\n",
    ")\n",
    "predictions = model.predictImage(image.toArray()).arrayFlatten([outBands])\n",
    "predictions.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clip the prediction area with the polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip the prediction area with the polygon\n",
    "polygon = ee.Geometry.Polygon(geometry.get('features')[0].get('geometry').get('coordinates'))\n",
    "predictions = predictions.clip(polygon)\n",
    "\n",
    "# Get centroid\n",
    "centroid = polygon.centroid().getInfo().get('coordinates')[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentate image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'segmentation':\n",
    "    maxValues = predictions.reduce(ee.Reducer.max())\n",
    "\n",
    "    predictions = predictions.addBands(maxValues)\n",
    "\n",
    "    expression = \"\"\n",
    "    for n, band in enumerate(outBands):\n",
    "        expression = expression + f\"(b('{band}') == b('max')) ? {str(n+1)} : \"\n",
    "\n",
    "    expression = expression + f\"0\"\n",
    "\n",
    "    segmentation = predictions.expression(expression)\n",
    "    predictions = predictions.addBands(segmentation.mask(segmentation).select(['constant'], ['categories']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display**\n",
    "\n",
    "Use folium to visualize the input imagery and the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL format used for Earth Engine generated map tiles.\n",
    "EE_TILES = 'https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}'\n",
    "\n",
    "mapid = image.getMapId({'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 1})\n",
    "map = folium.Map(location=centroid, zoom_start=12)\n",
    "folium.TileLayer(\n",
    "    tiles=EE_TILES.format(**mapid),\n",
    "    attr='Google Earth Engine',\n",
    "    overlay=True,\n",
    "    name='median composite',\n",
    "  ).add_to(map)\n",
    "\n",
    "for band in outBands:\n",
    "    mapid = predictions.getMapId({'bands': [band], 'min': 0, 'max': 0.5})\n",
    "    \n",
    "    folium.TileLayer(\n",
    "        tiles=EE_TILES.format(**mapid),\n",
    "        attr='Google Earth Engine',\n",
    "        overlay=True,\n",
    "        name=band,\n",
    "      ).add_to(map)\n",
    "\n",
    "\n",
    "if model_type == 'segmentation':\n",
    "    mapid = predictions.getMapId({'bands': ['categories'], 'min': 1, 'max': len(outBands)})\n",
    "    \n",
    "    folium.TileLayer(\n",
    "        tiles=EE_TILES.format(**mapid),\n",
    "        attr='Google Earth Engine',\n",
    "        overlay=True,\n",
    "        name='categories',\n",
    "      ).add_to(map)\n",
    "    \n",
    "map.add_child(folium.LayerControl())\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Predict in AI Platform\n",
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inCollection = 'Landsat8_SR'\n",
    "inBands = ['B1','B2','B3','B4','B5','B6','B7']\n",
    "outBands = ['cropland', 'land', 'water', 'urban']\n",
    "startDate = '2016-01-01'\n",
    "stopDate = '2016-12-31'\n",
    "scale = 30 #scale in meters\n",
    "\n",
    "# Model variables\n",
    "PROJECT_ID = env.project_id\n",
    "MODEL_NAME = 'segnet_Landsat8_Cropland'\n",
    "VERSION_NAME = VERSION_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify names of input locations in Cloud Storage.\n",
    "dataset_name = 'Landsat8_Cropland'\n",
    "job_dir = 'gs://' + bucket + '/' + 'cnn-models/' + dataset_name + '/trainer'\n",
    "model_dir = job_dir + '/model' \n",
    "\n",
    "exported_model_dirs = ! gsutil ls {model_dir}\n",
    "\n",
    "# Pick the directory with the latest timestamp, in case you've trained multiple times\n",
    "saved_model_path = exported_model_dirs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "MODEL_NAME = 'segnet_Landsat8_Cropland'\n",
    "VERSION_NAME = VERSION_NAME\n",
    "print('Creating version: ' + VERSION_NAME)\n",
    "\n",
    "!gcloud ai-platform models create {MODEL_NAME} \n",
    "\n",
    "# Create model version based on that SavedModel directory\n",
    "! gcloud ai-platform versions create {VERSION_NAME} \\\n",
    "  --model {MODEL_NAME} \\\n",
    "  --runtime-version 1.13 \\\n",
    "  --python-version 3.5 \\\n",
    "  --framework tensorflow \\\n",
    "  --origin {saved_model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetName = 'Landsat8_Cropland'\n",
    "baseNames = ['training_patches', 'eval_patches']\n",
    "inBands = ['B1','B2','B3','B4','B5','B6','B7']\n",
    "outBands = ['cropland', 'land', 'water', 'urban']\n",
    "        \n",
    "folder = 'cnn-models/'+datasetName+'/data'\n",
    "kernel_size = 256\n",
    "buffer_size = 100\n",
    "batch_size = 4\n",
    "\n",
    "glob = 'gs://' + env.bucket_name + '/' + folder + '/' + baseNames[0] + '_g0'+ '*'\n",
    "dataset = get_dataset(glob, inBands, outBands, kernel_size, buffer_size, batch_size)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_channels(input_arr[2,:80,:80,:], input_arr.shape[3], titles=inBands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Formatting input data for online prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = input_arr[2,:80,:80,:]\n",
    "data = np.around(data,2).tolist()\n",
    "instance = {\"image\" : data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requesting predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "import googleapiclient\n",
    "\n",
    "def predict_json(project, model, instances, privatekey_path, version=None):\n",
    "    \"\"\"Send json data to a deployed model for prediction.\n",
    "\n",
    "    Args:\n",
    "        project (str): project where the AI Platform Model is deployed.\n",
    "        model (str): model name.\n",
    "        instances ([Mapping[str: Any]]): Keys should be the names of Tensors\n",
    "            your deployed model expects as inputs. Values should be datatypes\n",
    "            convertible to Tensors, or (potentially nested) lists of datatypes\n",
    "            convertible to tensors.\n",
    "        version: str, version of the model to target.\n",
    "    Returns:\n",
    "        Mapping[str: any]: dictionary of prediction results defined by the\n",
    "            model.\n",
    "    \"\"\"    \n",
    "    # To authenticate set the GOOGLE_APPLICATION_CREDENTIALS\n",
    "    credentials = service_account.Credentials.from_service_account_file(privatekey_path)\n",
    "    \n",
    "    # Create the AI Platform service object.\n",
    "    service = googleapiclient.discovery.build('ml', 'v1', credentials=credentials)\n",
    "    name = 'projects/{}/models/{}'.format(project, model)\n",
    "\n",
    "    if version is not None:\n",
    "        name += '/versions/{}'.format(version)\n",
    "\n",
    "    response = service.projects().predict(\n",
    "        name=name,\n",
    "        body={'instances': instances}\n",
    "    ).execute()\n",
    "\n",
    "    if 'error' in response:\n",
    "        raise RuntimeError(response['error'])\n",
    "\n",
    "    return response['predictions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submit the online prediction request**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privatekey_path = 'privatekey.json'\n",
    "response = predict_json(project=PROJECT_ID, model=MODEL_NAME, instances=instance, privatekey_path=privatekey_path, version=VERSION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.array(response[0].get('output'))\n",
    "output.shape\n",
    "display_channels(output, output.shape[2], titles=['cropland', 'land', 'water', 'urban'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Data post-processing\n",
    "\n",
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
