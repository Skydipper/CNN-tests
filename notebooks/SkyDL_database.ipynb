{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database for Deep Learning with SkyDL\n",
    "**Setup software libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sqlalchemy\n",
    "from sqlalchemy import Column, Integer, BigInteger, Float, Text, String, Boolean, DateTime\n",
    "from sqlalchemy.dialects.postgresql import JSON\n",
    "from shapely.geometry import shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database\n",
    "\n",
    "We will create a Database to save all the attributes that we will generate all through the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_table(table_path, columns, dtypes):\n",
    "    if not os.path.exists(table_path):\n",
    "        dictionary = dict(zip(columns, dtypes))\n",
    "        dtypes = np.dtype([(k, v) for k, v in dictionary.items()]) \n",
    "    \n",
    "        data = np.empty(0, dtype=dtypes)\n",
    "        df = pd.DataFrame(data)\n",
    "    \n",
    "        df.to_csv(table_path, sep=';', quotechar='\\'',index=True, index_label='id')\n",
    "    else:\n",
    "        df = pd.read_csv(table_path, sep=';', quotechar='\\'').drop(columns='id')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Database'):\n",
    "    os.makedirs('Database')\n",
    "    \n",
    "datasets = create_db_table('Database/dataset.csv', \n",
    "                          columns = ['slug', 'name', 'bands', 'rgb_bands', 'provider'], \n",
    "                          dtypes = [str, str, list, list, str]\n",
    "                         )\n",
    "\n",
    "images = create_db_table('Database/image.csv', \n",
    "                          columns = ['dataset_id', 'bands_selections', 'scale', 'init_date',\n",
    "                                     'end_date', 'bands_min_max', 'norm_type'], \n",
    "                          dtypes = [int, list, float, str, str, str, str]\n",
    "                         )\n",
    "\n",
    "models = create_db_table('Database/model.csv', \n",
    "                          columns = ['model_name', 'model_type', 'model_output', 'model_description', 'output_image_id'], \n",
    "                          dtypes = [str, str, str, str, int]\n",
    "                        )\n",
    "                         \n",
    "versions = create_db_table('Database/model_versions.csv', \n",
    "                           columns = ['model_id', 'model_architecture', 'input_image_id', 'output_image_id', 'geostore_id', 'kernel_size', 'sample_size', \n",
    "                                      'training_params', 'version', 'data_status', 'training_status', 'eeified', 'deployed'], \n",
    "                           dtypes = [int, str, int, int, str, int, int, str, int, str, str, bool, bool]   \n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting Pandas to a Database with SQLAlchemy ([tutorial](https://hackersandslackers.com/connecting-pandas-to-a-sql-database-with-sqlalchemy/))\n",
    "\n",
    "#### Create an engine\n",
    "\n",
    "An `engine` is an object used to connect to databases using the information in our URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine('postgresql://postgres:postgres@0.0.0.0:5432/geomodels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create SQL tables from DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_db(df, table_name):\n",
    "    if table_name == \"dataset\":\n",
    "        df.to_sql(\"dataset\",\n",
    "                       engine,\n",
    "                       if_exists='replace',\n",
    "                       schema='public',\n",
    "                       index=True,\n",
    "                       index_label='id',\n",
    "                       chunksize=500,\n",
    "                       dtype={\"slug\": Text,\n",
    "                              \"name\": Text,\n",
    "                              \"bands\": Text,\n",
    "                              \"bands\": Text,\n",
    "                              \"provider\": Text})\n",
    "    if table_name == \"image\":\n",
    "        df.to_sql(\"image\",\n",
    "                       engine,\n",
    "                       if_exists='replace',\n",
    "                       schema='public',\n",
    "                       index=True,\n",
    "                       index_label='id',\n",
    "                       chunksize=500,\n",
    "                       dtype={\"dataset_id \": Integer,\n",
    "                              \"bands_selections\": Text,\n",
    "                              \"scale\": Float,\n",
    "                              \"init_date\": Text,\n",
    "                              \"end_date\": Text,\n",
    "                              \"bands_min_max\": JSON,\n",
    "                              \"norm_type\": Text})\n",
    "    \n",
    "    if table_name == \"model\":\n",
    "        df.to_sql(\"model\",\n",
    "                       engine,\n",
    "                       if_exists='replace',\n",
    "                       schema='public',\n",
    "                       index=True,\n",
    "                       index_label='id',\n",
    "                       chunksize=500,\n",
    "                       dtype={\"model_name\": Text,\n",
    "                              \"model_type\": Text,\n",
    "                              \"model_output\": Text,\n",
    "                              \"model_description\": Text,\n",
    "                              \"output_image_id\": Integer})\n",
    "    \n",
    "    if table_name == \"model_versions\":\n",
    "        df.to_sql(\"model_versions\",\n",
    "                       engine,\n",
    "                       if_exists='replace',\n",
    "                       schema='public',\n",
    "                       index=True,\n",
    "                       index_label='id',\n",
    "                       chunksize=500,\n",
    "                       dtype={\"model_id\": Integer,\n",
    "                              \"model_architecture\": Text,\n",
    "                              \"input_image_id\": Integer,\n",
    "                              \"output_image_id\": Integer,\n",
    "                              \"geostore_id\": Text,\n",
    "                              \"kernel_size\": BigInteger,\n",
    "                              \"sample_size\": BigInteger,\n",
    "                              \"training_params\": JSON,\n",
    "                              \"version\": BigInteger,\n",
    "                              \"data_status\": Text,\n",
    "                              \"training_status\": Text,\n",
    "                              \"eeified\": Boolean,\n",
    "                              \"deployed\": Boolean})   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not engine.dialect.has_table(engine, \"dataset\"):\n",
    "    datasets = pd.read_csv('Database/dataset.csv', sep=';', quotechar='\\'').drop(columns='id')\n",
    "if not engine.dialect.has_table(engine, \"image\"):\n",
    "    images = pd.read_csv('Database/image.csv', sep=';', quotechar='\\'').drop(columns='id')\n",
    "if not engine.dialect.has_table(engine, \"model\"):\n",
    "    models = pd.read_csv('Database/model.csv', sep=';', quotechar='\\'').drop(columns='id')\n",
    "if not engine.dialect.has_table(engine, \"model_versions\"):\n",
    "    versions = pd.read_csv('Database/model_versions.csv', sep=';', quotechar='\\'').drop(columns='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save SQL tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not engine.dialect.has_table(engine, \"dataset\"):\n",
    "    df_to_db(datasets, \"dataset\")\n",
    "if not engine.dialect.has_table(engine, \"image\"):\n",
    "    df_to_db(images, \"image\")\n",
    "if not engine.dialect.has_table(engine, \"model\"):\n",
    "    df_to_db(models, \"model\")\n",
    "if not engine.dialect.has_table(engine, \"model_versions\"):\n",
    "    df_to_db(versions, \"model_versions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate `dataset` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slugs_list = [\"Sentinel-2-Top-of-Atmosphere-Reflectance\",\n",
    "              \"Landsat-7-Surface-Reflectance\",\n",
    "              \"Landsat-8-Surface-Reflectance\",\n",
    "              \"USDA-NASS-Cropland-Data-Layers\",\n",
    "              \"USGS-National-Land-Cover-Database\",\n",
    "              \"Lake-Water-Quality-100m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Skydipper.Collection(search=' '.join(slugs_list), object_type=['dataset'], app=['skydipper'], limit=10)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read table\n",
    "datasets = df_from_query('dataset')\n",
    "\n",
    "for collection in slugs_list:\n",
    "\n",
    "    ds = Skydipper.Dataset(id_hash=collection)\n",
    "    name = ds.attributes.get('name')\n",
    "    provider = ds.attributes.get('provider')\n",
    "\n",
    "    bands = [str(ee_collection_specifics.ee_bands(collection))]\n",
    "    rgb_bands = [str(ee_collection_specifics.ee_bands_rgb(collection))]\n",
    "\n",
    "\n",
    "    dictionary = dict(zip(list(datasets.keys()), [collection, name, bands, rgb_bands, provider]))\n",
    "    \n",
    "    if (datasets['slug'] == collection).any():\n",
    "        datasets = datasets\n",
    "    else:\n",
    "        datasets = datasets.append(pd.DataFrame(dictionary), ignore_index = True)\n",
    "        \n",
    "        # Save table\n",
    "        df_to_csv(datasets, \"dataset\")\n",
    "        df_to_db(datasets, \"dataset\")\n",
    "    \n",
    "datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
