{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water quality\n",
    "## Setup software libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.202'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and initialize the Earth Engine library.\n",
    "import ee\n",
    "ee.Initialize()\n",
    "ee.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.3\n"
     ]
    }
   ],
   "source": [
    "# Folium setup.\n",
    "import folium\n",
    "print(folium.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.7\n"
     ]
    }
   ],
   "source": [
    "# Skydipper library.\n",
    "import Skydipper\n",
    "print(Skydipper.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import functools\n",
    "import json\n",
    "import uuid\n",
    "import os\n",
    "from pprint import pprint\n",
    "import env\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee_collection_specifics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composite image\n",
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = 'Lake-Water-Quality-100m'\n",
    "init_date = '2019-01-21'\n",
    "end_date = '2019-01-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x112276b38>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the URL format used for Earth Engine generated map tiles.\n",
    "EE_TILES = 'https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}'\n",
    "\n",
    "composite = ee_collection_specifics.Composite(collection)(init_date, end_date)\n",
    "mapid = composite.getMapId(ee_collection_specifics.vizz_params_rgb(collection))\n",
    "\n",
    "tiles_url = EE_TILES.format(**mapid)\n",
    "\n",
    "map = folium.Map(location=[39.31, 0.302])\n",
    "folium.TileLayer(\n",
    "tiles=tiles_url,\n",
    "attr='Google Earth Engine',\n",
    "overlay=True,\n",
    "name=str(ee_collection_specifics.ee_bands_rgb(collection))).add_to(map)\n",
    "    \n",
    "map.add_child(folium.LayerControl())\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Geostore\n",
    "\n",
    "We select the areas from which we will export the training data.\n",
    "\n",
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygons_to_multipoligon(polygons):\n",
    "    multipoligon = []\n",
    "    MultiPoligon = {}\n",
    "    for polygon in polygons.get('features'):\n",
    "        multipoligon.append(polygon.get('geometry').get('coordinates'))\n",
    "        \n",
    "    MultiPoligon = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": [\n",
    "            {\n",
    "                \"type\": \"Feature\",\n",
    "                \"properties\": {},\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"MultiPolygon\",\n",
    "                    \"coordinates\":  multipoligon\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return MultiPoligon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainPolygons = {\"type\":\"FeatureCollection\",\"features\":[{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-0.45043945312499994,39.142842478062505],[0.06042480468749999,39.142842478062505],[0.06042480468749999,39.55064761909318],[-0.45043945312499994,39.55064761909318],[-0.45043945312499994,39.142842478062505]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-0.2911376953125,38.659777730712534],[0.2581787109375,38.659777730712534],[0.2581787109375,39.10022600175347],[-0.2911376953125,39.10022600175347],[-0.2911376953125,38.659777730712534]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-0.3350830078125,39.56758783088905],[0.22521972656249997,39.56758783088905],[0.22521972656249997,39.757879992021756],[-0.3350830078125,39.757879992021756],[-0.3350830078125,39.56758783088905]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[0.07965087890625,39.21310328979648],[0.23345947265625,39.21310328979648],[0.23345947265625,39.54852980171147],[0.07965087890625,39.54852980171147],[0.07965087890625,39.21310328979648]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-1.0931396484375,35.7286770448517],[-0.736083984375,35.7286770448517],[-0.736083984375,35.94243575255426],[-1.0931396484375,35.94243575255426],[-1.0931396484375,35.7286770448517]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-1.7303466796874998,35.16931803601131],[-1.4666748046875,35.16931803601131],[-1.4666748046875,35.74205383068037],[-1.7303466796874998,35.74205383068037],[-1.7303466796874998,35.16931803601131]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-1.42822265625,35.285984736065764],[-1.131591796875,35.285984736065764],[-1.131591796875,35.782170703266075],[-1.42822265625,35.782170703266075],[-1.42822265625,35.285984736065764]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-1.8127441406249998,35.831174956246535],[-1.219482421875,35.831174956246535],[-1.219482421875,36.04465753921525],[-1.8127441406249998,36.04465753921525],[-1.8127441406249998,35.831174956246535]]]}}]}\n",
    "trainPolygons = {\"type\":\"FeatureCollection\",\"features\":[{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-0.406494140625,38.64476310916202],[0.27740478515625,38.64476310916202],[0.27740478515625,39.74521015328692],[-0.406494140625,39.74521015328692],[-0.406494140625,38.64476310916202]]]}},{\"type\":\"Feature\",\"properties\":{},\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[[[-1.70013427734375,35.15135442846945],[-0.703125,35.15135442846945],[-0.703125,35.94688293218141],[-1.70013427734375,35.94688293218141],[-1.70013427734375,35.15135442846945]]]}}]}\n",
    "trainPolys = polygons_to_multipoligon(trainPolygons)\n",
    "\n",
    "evalPolys = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training polygons: 2\n"
     ]
    }
   ],
   "source": [
    "nTrain = len(trainPolys.get('features')[0].get('geometry').get('coordinates'))\n",
    "print('Number of training polygons:',  nTrain)\n",
    "\n",
    "if evalPolys:\n",
    "    nEval = len(evalPolys.get('features')[0].get('geometry').get('coordinates'))\n",
    "    print('Number of training polygons:',  nEval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display Polygons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x112276be0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the URL format used for Earth Engine generated map tiles.\n",
    "EE_TILES = 'https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}'\n",
    "\n",
    "composite = ee_collection_specifics.Composite(collection)(init_date, end_date)\n",
    "mapid = composite.getMapId(ee_collection_specifics.vizz_params_rgb(collection))\n",
    "\n",
    "tiles_url = EE_TILES.format(**mapid)\n",
    "\n",
    "map = folium.Map(location=[39.31, 0.302], zoom_start=6)\n",
    "folium.TileLayer(\n",
    "tiles=tiles_url,\n",
    "attr='Google Earth Engine',\n",
    "overlay=True,\n",
    "name=str(ee_collection_specifics.ee_bands_rgb(collection))).add_to(map)\n",
    "    \n",
    "\n",
    "#  Convert the GeoJSONs to feature collections\n",
    "trainFeatures = ee.FeatureCollection(trainPolys.get('features'))\n",
    "if evalPolys:\n",
    "    evalFeatures = ee.FeatureCollection(evalPolys.get('features'))\n",
    "    \n",
    "polyImage = ee.Image(0).byte().paint(trainFeatures, 1)\n",
    "if evalPolys:\n",
    "    polyImage = ee.Image(0).byte().paint(trainFeatures, 1).paint(evalFeatures, 2)\n",
    "polyImage = polyImage.updateMask(polyImage)\n",
    "\n",
    "mapid = polyImage.getMapId({'min': 1, 'max': 2, 'palette': ['red', 'blue']})\n",
    "folium.TileLayer(\n",
    "    tiles=EE_TILES.format(**mapid),\n",
    "    attr='Google Earth Engine',\n",
    "    overlay=True,\n",
    "    name='training polygons',\n",
    "  ).add_to(map)\n",
    "\n",
    "map.add_child(folium.LayerControl())\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Data pre-processing\n",
    "\n",
    "We normalize the composite images to have values from 0 to 1.\n",
    "\n",
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = 'Sentinel-2-Top-of-Atmosphere-Reflectance'\n",
    "output_dataset = 'Lake-Water-Quality-100m'\n",
    "init_date = '2019-01-21'\n",
    "end_date = '2019-01-31'\n",
    "scale = 100 #scale in meters\n",
    "collections = [input_dataset, output_dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_values(image, collection, scale, polygons=None):\n",
    "    \n",
    "    normThreshold = ee_collection_specifics.ee_bands_normThreshold(collection)\n",
    "    \n",
    "    num = 2\n",
    "    lon = np.linspace(-180, 180, num)\n",
    "    lat = np.linspace(-90, 90, num)\n",
    "    \n",
    "    features = []\n",
    "    for i in range(len(lon)-1):\n",
    "        for j in range(len(lat)-1):\n",
    "            features.append(ee.Feature(ee.Geometry.Rectangle(lon[i], lat[j], lon[i+1], lat[j+1])))\n",
    "            \n",
    "    if not polygons:\n",
    "        polygons = ee.FeatureCollection(features)\n",
    "    \n",
    "    regReducer = {\n",
    "        'geometry': polygons,\n",
    "        'reducer': ee.Reducer.minMax(),\n",
    "        'maxPixels': 1e10,\n",
    "        'bestEffort': True,\n",
    "        'scale':scale,\n",
    "        'tileScale': 10\n",
    "        \n",
    "    }\n",
    "    \n",
    "    values = image.reduceRegion(**regReducer).getInfo()\n",
    "    print(values)\n",
    "    \n",
    "    # Avoid outliers by taking into account only the normThreshold% of the data points.\n",
    "    regReducer = {\n",
    "        'geometry': polygons, \n",
    "        'reducer': ee.Reducer.histogram(),\n",
    "        'maxPixels': 1e10,\n",
    "        'bestEffort': True,\n",
    "        'scale':scale,\n",
    "        'tileScale': 10\n",
    "        \n",
    "    }\n",
    "    \n",
    "    hist = image.reduceRegion(**regReducer).getInfo()\n",
    "\n",
    "    for band in list(normThreshold.keys()):\n",
    "        if normThreshold[band] != 100:\n",
    "            count = np.array(hist.get(band).get('histogram'))\n",
    "            x = np.array(hist.get(band).get('bucketMeans'))\n",
    "        \n",
    "            cumulative_per = np.cumsum(count/count.sum()*100)\n",
    "        \n",
    "            values[band+'_max'] = x[np.where(cumulative_per < normThreshold[band])][-1]\n",
    "        \n",
    "    return values\n",
    "\n",
    "def normalize_ee_images(image, collection, values):\n",
    "    \n",
    "    Bands = ee_collection_specifics.ee_bands(collection)\n",
    "       \n",
    "    # Normalize [0, 1] ee images\n",
    "    for i, band in enumerate(Bands):\n",
    "        if i == 0:\n",
    "            image_new = image.select(band).clamp(values[band+'_min'], values[band+'_max'])\\\n",
    "                                .subtract(values[band+'_min'])\\\n",
    "                                .divide(values[band+'_max']-values[band+'_min'])\n",
    "        else:\n",
    "            image_new = image_new.addBands(image.select(band).clamp(values[band+'_min'], values[band+'_max'])\\\n",
    "                                    .subtract(values[band+'_min'])\\\n",
    "                                    .divide(values[band+'_max']-values[band+'_min']))\n",
    "            \n",
    "    return image_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B11_max': 10857.5, 'B11_min': 7.0, 'B12_max': 10691.0, 'B12_min': 1.0, 'B1_max': 6806.0, 'B1_min': 983.0, 'B2_max': 6406.0, 'B2_min': 685.0, 'B3_max': 6182.0, 'B3_min': 412.0, 'B4_max': 7485.5, 'B4_min': 229.0, 'B5_max': 8444.0, 'B5_min': 186.0, 'B6_max': 9923.0, 'B6_min': 153.0, 'B7_max': 11409.0, 'B7_min': 128.0, 'B8A_max': 12957.0, 'B8A_min': 84.0, 'B8_max': 7822.0, 'B8_min': 104.0, 'ndvi_max': 0.8359633027522936, 'ndvi_min': -0.6463519313304721, 'ndwi_max': 0.7134948096885814, 'ndwi_min': -0.8102189781021898}\n",
      "{'B11_max': 10857.5, 'B11_min': 7.0, 'B12_max': 10691.0, 'B12_min': 1.0, 'B1_max': 1330.4577965925364, 'B1_min': 983.0, 'B2_max': 1039.5402534802865, 'B2_min': 685.0, 'B3_max': 879.698114934553, 'B3_min': 412.0, 'B4_max': 751.6494664084341, 'B4_min': 229.0, 'B5_max': 1119.607360754671, 'B5_min': 186.0, 'B6_max': 1823.92697289679, 'B6_min': 153.0, 'B7_max': 2079.961473786427, 'B7_min': 128.0, 'B8A_max': 2207.831974029281, 'B8A_min': 84.0, 'B8_max': 2031.6418424876374, 'B8_min': 104.0, 'ndvi_max': 0.8359633027522936, 'ndvi_min': -0.6463519313304721, 'ndwi_max': 0.7134948096885814, 'ndwi_min': -0.8102189781021898}\n",
      "CPU times: user 45.8 ms, sys: 4.96 ms, total: 50.7 ms\n",
      "Wall time: 9.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "images = []\n",
    "for collection in collections:\n",
    "    # Create composite\n",
    "    image = ee_collection_specifics.Composite(collection)(init_date, end_date)\n",
    "    \n",
    "    bands = ee_collection_specifics.ee_bands(collection)\n",
    "    image = image.select(bands)\n",
    "    \n",
    "    #Create composite\n",
    "    if ee_collection_specifics.normalize(collection):\n",
    "        # Get min man values for each band\n",
    "        values = min_max_values(image, collection, scale, polygons=trainFeatures)\n",
    "        print(values)\n",
    "    \n",
    "        # Normalize images\n",
    "        image = normalize_ee_images(image, collection, values)\n",
    "    else:\n",
    "        values = {}\n",
    "        \n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display composite**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,<!DOCTYPE html>
<head>    
    <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
    <script>L_PREFER_CANVAS=false; L_NO_TOUCH=false; L_DISABLE_3D=false;</script>
    <script src="https://cdn.jsdelivr.net/npm/leaflet@1.4.0/dist/leaflet.js"></script>
    <script src="https://code.jquery.com/jquery-1.12.4.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.4.0/dist/leaflet.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css"/>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css"/>
    <link rel="stylesheet" href="https://rawcdn.githack.com/python-visualization/folium/master/folium/templates/leaflet.awesome.rotate.css"/>
    <style>html, body {width: 100%;height: 100%;margin: 0;padding: 0;}</style>
    <style>#map {position:absolute;top:0;bottom:0;right:0;left:0;}</style>
    
    <meta name="viewport" content="width=device-width,
        initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <style>#map_4da6a9540fd247b286b02f90e2566563 {
        position: relative;
        width: 100.0%;
        height: 100.0%;
        left: 0.0%;
        top: 0.0%;
        }
    </style>
</head>
<body>    
    
    <div class="folium-map" id="map_4da6a9540fd247b286b02f90e2566563" ></div>
</body>
<script>    
    
    
        var bounds = null;
    

    var map_4da6a9540fd247b286b02f90e2566563 = L.map(
        'map_4da6a9540fd247b286b02f90e2566563', {
        center: [39.31, 0.302],
        zoom: 6,
        maxBounds: bounds,
        layers: [],
        worldCopyJump: false,
        crs: L.CRS.EPSG3857,
        zoomControl: true,
        });


    
    var tile_layer_4637385386274442a070a6676fea2097 = L.tileLayer(
        'https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png',
        {
        "attribution": null,
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_4da6a9540fd247b286b02f90e2566563);
    var tile_layer_143511d23f0d4607af53ce8cc7e54f00 = L.tileLayer(
        'https://earthengine.googleapis.com/map/944c93cd4f307e7f3dbbc4e6e30d1202/{z}/{x}/{y}?token=583a77e6001de1249b5d61c52f95d102',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_4da6a9540fd247b286b02f90e2566563);
    var tile_layer_6c45f72b1b934062b0adf2c7bd479fc3 = L.tileLayer(
        'https://earthengine.googleapis.com/map/9f2fc792043073e1a541a108d9cbcfcd/{z}/{x}/{y}?token=168a665ebe5ea670905d089ac6c2e76e',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_4da6a9540fd247b286b02f90e2566563);
    var tile_layer_a7cf7b2f603243da87f6127590f65d42 = L.tileLayer(
        'https://earthengine.googleapis.com/map/ff4608f7bdfa1086d2684438d26259d1/{z}/{x}/{y}?token=3ec9fbfd0b6e8a19075d9ce0d5bba037',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_4da6a9540fd247b286b02f90e2566563);
    var tile_layer_632a60632e54442fbb14f0a662699d5d = L.tileLayer(
        'https://earthengine.googleapis.com/map/a7765f8de34c920d89ab5ee9a5e200c1/{z}/{x}/{y}?token=17fa20a43deef218ac32aae4655f7389',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_4da6a9540fd247b286b02f90e2566563);
    var tile_layer_f0c030eedb6c40b29a32f3ff0264412b = L.tileLayer(
        'https://earthengine.googleapis.com/map/9b5ba88c46214350f920b097e66c79d4/{z}/{x}/{y}?token=de008956c3fc1a54771d71048ce9161c',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_4da6a9540fd247b286b02f90e2566563);
    var tile_layer_2103fbaa358c4a11b9acbbeea0f855dd = L.tileLayer(
        'https://earthengine.googleapis.com/map/17562a2d4a0ff547a9fd309717ac7dff/{z}/{x}/{y}?token=3ed7b32baef298a6dda6ec6cdb2b4089',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_4da6a9540fd247b286b02f90e2566563);
    var tile_layer_e23dff9e26514d0c85fbf318f7eec83b = L.tileLayer(
        'https://earthengine.googleapis.com/map/22fb1c4286de14cf12d3f9412f9c44ba/{z}/{x}/{y}?token=811fe247bb589ff5167e1a0c75be612d',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_4da6a9540fd247b286b02f90e2566563);
    var tile_layer_be5247c47637413ba343f1ed08cfae1b = L.tileLayer(
        'https://earthengine.googleapis.com/map/f661f60698b09833e4c5286adc467578/{z}/{x}/{y}?token=dabc8d77813e46279a54c1cf687fd311',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_4da6a9540fd247b286b02f90e2566563);
    var tile_layer_ff0ded0dc25d4f0dbc3a1cb7fdfea92c = L.tileLayer(
        'https://earthengine.googleapis.com/map/55ceb881420ef1720bff7f884eef9b45/{z}/{x}/{y}?token=6c9a06e2e5226818157061c75c7c604c',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_4da6a9540fd247b286b02f90e2566563);
    var tile_layer_58a060bbc67f4f33a4259d44fe09ee4c = L.tileLayer(
        'https://earthengine.googleapis.com/map/f276597e78dbf502b20381c98a4d6fa2/{z}/{x}/{y}?token=d92b76d4b6042714cd3b025eb19d2c0a',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_4da6a9540fd247b286b02f90e2566563);
    var tile_layer_9534199a61314f58a443b92e848c5421 = L.tileLayer(
        'https://earthengine.googleapis.com/map/7c62f9b702b8419ae12f6007d8c6384f/{z}/{x}/{y}?token=d89981dccf1078315a84ab4f2f16af7a',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_4da6a9540fd247b286b02f90e2566563);
    var tile_layer_a13be8a9ff524941a7b1ee2bcf8bc367 = L.tileLayer(
        'https://earthengine.googleapis.com/map/709c18cf24cee8d0a31d47912f206afe/{z}/{x}/{y}?token=5137e6799442a99dff07cbfd9adb0214',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_4da6a9540fd247b286b02f90e2566563);
    var tile_layer_2be6808ecbbf499da36d24ac8fbf8c6d = L.tileLayer(
        'https://earthengine.googleapis.com/map/ae57c061bc52384cf95e5f8e83bc7bcf/{z}/{x}/{y}?token=ab225339534688706f3093e0ae25402a',
        {
        "attribution": "Google Earth Engine",
        "detectRetina": false,
        "maxNativeZoom": 18,
        "maxZoom": 18,
        "minZoom": 0,
        "noWrap": false,
        "opacity": 1,
        "subdomains": "abc",
        "tms": false
}).addTo(map_4da6a9540fd247b286b02f90e2566563);
    
            var layer_control_ac9d5b3fd2ce494a94e85497da70404f = {
                base_layers : { "openstreetmap" : tile_layer_4637385386274442a070a6676fea2097, },
                overlays : { "['B4', 'B3', 'B2']" : tile_layer_143511d23f0d4607af53ce8cc7e54f00,"['B1']" : tile_layer_6c45f72b1b934062b0adf2c7bd479fc3,"['B5']" : tile_layer_a7cf7b2f603243da87f6127590f65d42,"['B6']" : tile_layer_632a60632e54442fbb14f0a662699d5d,"['B7']" : tile_layer_f0c030eedb6c40b29a32f3ff0264412b,"['B8A']" : tile_layer_2103fbaa358c4a11b9acbbeea0f855dd,"['B8']" : tile_layer_e23dff9e26514d0c85fbf318f7eec83b,"['B11']" : tile_layer_be5247c47637413ba343f1ed08cfae1b,"['B12']" : tile_layer_ff0ded0dc25d4f0dbc3a1cb7fdfea92c,"['ndvi']" : tile_layer_58a060bbc67f4f33a4259d44fe09ee4c,"['ndwi']" : tile_layer_9534199a61314f58a443b92e848c5421,"['turbidity_blended_mean']" : tile_layer_a13be8a9ff524941a7b1ee2bcf8bc367,"training polygons" : tile_layer_2be6808ecbbf499da36d24ac8fbf8c6d, }
                };
            L.control.layers(
                layer_control_ac9d5b3fd2ce494a94e85497da70404f.base_layers,
                layer_control_ac9d5b3fd2ce494a94e85497da70404f.overlays,
                {position: 'topright',
                 collapsed: true,
                 autoZIndex: true
                }).addTo(map_4da6a9540fd247b286b02f90e2566563);
            
        
</script>\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x1123460f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the URL format used for Earth Engine generated map tiles.\n",
    "EE_TILES = 'https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}'\n",
    "map = folium.Map(location=[39.31, 0.302], zoom_start=6)\n",
    "for n, collection in enumerate(collections):\n",
    "    for params in ee_collection_specifics.vizz_params(collection):\n",
    "        mapid = images[n].getMapId(params)\n",
    "        folium.TileLayer(\n",
    "        tiles=EE_TILES.format(**mapid),\n",
    "        attr='Google Earth Engine',\n",
    "        overlay=True,\n",
    "        name=str(params['bands']),\n",
    "      ).add_to(map)\n",
    "        \n",
    "#  Convert the GeoJSONs to feature collections\n",
    "trainFeatures = ee.FeatureCollection(trainPolys.get('features'))\n",
    "if evalPolys:\n",
    "    evalFeatures = ee.FeatureCollection(evalPolys.get('features'))\n",
    "    \n",
    "polyImage = ee.Image(0).byte().paint(trainFeatures, 1)\n",
    "if evalPolys:\n",
    "    polyImage = ee.Image(0).byte().paint(trainFeatures, 1).paint(evalFeatures, 2)\n",
    "polyImage = polyImage.updateMask(polyImage)\n",
    "\n",
    "mapid = polyImage.getMapId({'min': 1, 'max': 2, 'palette': ['red', 'blue']})\n",
    "folium.TileLayer(\n",
    "    tiles=EE_TILES.format(**mapid),\n",
    "    attr='Google Earth Engine',\n",
    "    overlay=True,\n",
    "    name='training polygons',\n",
    "  ).add_to(map)\n",
    "\n",
    "map.add_child(folium.LayerControl())\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Create TFRecords for training\n",
    "### Export pixels\n",
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_bands = ['B2','B3','B4','B5','ndvi','ndwi']\n",
    "output_bands = ['turbidity_blended_mean']\n",
    "bands = [input_bands, output_bands]\n",
    "\n",
    "dataset_name = 'Sentinel2_WaterQuality'\n",
    "base_names = ['training_pixels', 'eval_pixels']\n",
    "bucket = env.bucket_name\n",
    "folder = 'cnn-models/'+dataset_name+'/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select the bands**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bands': [{'crs': 'EPSG:4326',\n",
      "            'crs_transform': [1.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
      "            'data_type': {'max': 1.0,\n",
      "                          'min': 0.0,\n",
      "                          'precision': 'double',\n",
      "                          'type': 'PixelType'},\n",
      "            'id': 'B2'},\n",
      "           {'crs': 'EPSG:4326',\n",
      "            'crs_transform': [1.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
      "            'data_type': {'max': 1.0,\n",
      "                          'min': 0.0,\n",
      "                          'precision': 'double',\n",
      "                          'type': 'PixelType'},\n",
      "            'id': 'B3'},\n",
      "           {'crs': 'EPSG:4326',\n",
      "            'crs_transform': [1.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
      "            'data_type': {'max': 1.0,\n",
      "                          'min': 0.0,\n",
      "                          'precision': 'double',\n",
      "                          'type': 'PixelType'},\n",
      "            'id': 'B4'},\n",
      "           {'crs': 'EPSG:4326',\n",
      "            'crs_transform': [1.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
      "            'data_type': {'max': 1.0,\n",
      "                          'min': 0.0,\n",
      "                          'precision': 'double',\n",
      "                          'type': 'PixelType'},\n",
      "            'id': 'B5'},\n",
      "           {'crs': 'EPSG:4326',\n",
      "            'crs_transform': [1.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
      "            'data_type': {'max': 1.000000004087453,\n",
      "                          'min': -1.449649135231728e-09,\n",
      "                          'precision': 'double',\n",
      "                          'type': 'PixelType'},\n",
      "            'id': 'ndvi'},\n",
      "           {'crs': 'EPSG:4326',\n",
      "            'crs_transform': [1.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
      "            'data_type': {'max': 1.0000000181106892,\n",
      "                          'min': -7.70938799632259e-09,\n",
      "                          'precision': 'double',\n",
      "                          'type': 'PixelType'},\n",
      "            'id': 'ndwi'},\n",
      "           {'crs': 'EPSG:4326',\n",
      "            'crs_transform': [0.000898311174991017,\n",
      "                              0.0,\n",
      "                              -10.06198347107437,\n",
      "                              0.0,\n",
      "                              -0.000898311174991017,\n",
      "                              43.89328063241106],\n",
      "            'data_type': {'precision': 'float', 'type': 'PixelType'},\n",
      "            'dimensions': [15043, 10004],\n",
      "            'id': 'turbidity_blended_mean'}],\n",
      " 'type': 'Image'}\n"
     ]
    }
   ],
   "source": [
    "# Select the bands we want\n",
    "c = images[0].select(bands[0])\\\n",
    ".addBands(images[1].select(bands[1]))\n",
    "\n",
    "pprint(c.getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample pixels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = c.sample(region = trainFeatures, scale = scale, numPixels=20000, tileScale=4, seed=999)\n",
    "\n",
    "# Add random column\n",
    "sr = sr.randomColumn(seed=999)\n",
    "\n",
    "# Partition the sample approximately 70-30.\n",
    "train_dataset = sr.filter(ee.Filter.lt('random', 0.7))\n",
    "eval_dataset = sr.filter(ee.Filter.gte('random', 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training': {'geometry': None,\n",
      "              'id': '6',\n",
      "              'properties': {'B2': 0.8574484759229273,\n",
      "                             'B3': 0.3634823288175725,\n",
      "                             'B4': 0.12149634522036754,\n",
      "                             'B5': 0.05248459048179677,\n",
      "                             'ndvi': 0.18857628593212067,\n",
      "                             'ndwi': 0.12332980645053383,\n",
      "                             'random': 0.2613394930887267,\n",
      "                             'turbidity_blended_mean': 0.24297301471233368},\n",
      "              'type': 'Feature'}}\n",
      "{'testing': {'geometry': None,\n",
      "             'id': '9',\n",
      "             'properties': {'B2': 0.8447559820359103,\n",
      "                            'B3': 0.36455139449056534,\n",
      "                            'B4': 0.11097303972883964,\n",
      "                            'B5': 0.049271248207401044,\n",
      "                            'ndvi': 0.18537677513643622,\n",
      "                            'ndwi': 0.11719150831907015,\n",
      "                            'random': 0.7072425790569007,\n",
      "                            'turbidity_blended_mean': 0.2145373672246933},\n",
      "             'type': 'Feature'}}\n"
     ]
    }
   ],
   "source": [
    "# Print the first couple points to verify.\n",
    "pprint({'training': train_dataset.first().getInfo()})\n",
    "pprint({'testing': eval_dataset.first().getInfo()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training': 8091}\n",
      "{'testing': 3508}\n"
     ]
    }
   ],
   "source": [
    "# Print the first couple points to verify.\n",
    "from pprint import pprint\n",
    "train_size=train_dataset.size().getInfo()\n",
    "eval_size=eval_dataset.size().getInfo()\n",
    "\n",
    "pprint({'training': train_size})\n",
    "pprint({'testing': eval_size})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export the training and validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_TFRecords_pixels(datasets, base_names, bucket, folder, selectors):\n",
    "    # Export all the training/evaluation data \n",
    "    \n",
    "    filePaths = []\n",
    "    for n, dataset in enumerate(datasets):\n",
    "        \n",
    "        filePaths.append(bucket+ '/' + folder + '/' + base_names[n])\n",
    "        \n",
    "        # Create the tasks.\n",
    "        task = ee.batch.Export.table.toCloudStorage(\n",
    "          collection = dataset,\n",
    "          description = 'Export '+base_names[n],\n",
    "          fileNamePrefix = folder + '/' + base_names[n],\n",
    "          bucket = bucket,\n",
    "          fileFormat = 'TFRecord',\n",
    "          selectors = selectors)\n",
    "        \n",
    "        task.start()\n",
    "            \n",
    "    return filePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [train_dataset, eval_dataset]\n",
    "selectors = input_bands + output_bands\n",
    "\n",
    "# Export training/evaluation data\n",
    "filePaths = export_TFRecords_pixels(datasets, base_names, bucket, folder, selectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Inspect data\n",
    "### Inspect pixels\n",
    "Load the data exported from Earth Engine into a tf.data.Dataset. \n",
    "\n",
    "**Helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow setup.\n",
    "import tensorflow as tf\n",
    "\n",
    "if tf.__version__ == '1.15.0':\n",
    "    tf.enable_eager_execution()\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function(proto):\n",
    "    \"\"\"The parsing function.\n",
    "    Read a serialized example into the structure defined by FEATURES_DICT.\n",
    "    Args:\n",
    "      example_proto: a serialized Example.\n",
    "    Returns: \n",
    "      A tuple of the predictors dictionary and the labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define your tfrecord \n",
    "    features = input_bands + output_bands\n",
    "    \n",
    "    # Specify the size and shape of patches expected by the model.\n",
    "    columns = [\n",
    "      tf.io.FixedLenFeature(shape=[1,1], dtype=tf.float32) for k in features\n",
    "    ]\n",
    "    \n",
    "    features_dict = dict(zip(features, columns))\n",
    "    \n",
    "    # Load one example\n",
    "    parsed_features = tf.io.parse_single_example(proto, features_dict)\n",
    "    \n",
    "    # Convert a dictionary of tensors to a tuple of (inputs, outputs)\n",
    "    inputsList = [parsed_features.get(key) for key in features]\n",
    "    stacked = tf.stack(inputsList, axis=0)\n",
    "    \n",
    "    # Convert the tensors into a stack in HWC shape\n",
    "    stacked = tf.transpose(stacked, [1, 2, 0])\n",
    "    \n",
    "    return stacked[:,:,:len(input_bands)], stacked[:,:,len(input_bands):]\n",
    "\n",
    "def get_dataset(glob, buffer_size, batch_size):\n",
    "    \"\"\"Get the dataset\n",
    "    Returns: \n",
    "    A tf.data.Dataset of training data.\n",
    "    \"\"\"\n",
    "    glob = tf.compat.v1.io.gfile.glob(glob)\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=5)\n",
    "    \n",
    "    dataset = dataset.shuffle(buffer_size).batch(batch_size).repeat()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 100\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((?, 1, 1, 6), (?, 1, 1, 1)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob = 'gs://' + bucket + '/' + folder + '/' + base_names[0] + '*'\n",
    "dataset = get_dataset(glob, buffer_size, batch_size)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the first record**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 1, 6)\n",
      "(4, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "arr = iter(dataset.take(1)).next()\n",
    "input_arr = arr[0].numpy()\n",
    "print(input_arr.shape)\n",
    "output_arr = arr[1].numpy()\n",
    "print(output_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Training the model locally\n",
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_dir = 'gs://' + bucket + '/' + 'cnn-models/'+ dataset_name +'/trainer'\n",
    "logs_dir = job_dir + '/logs'\n",
    "model_dir = job_dir + '/model'\n",
    "shuffle_size = 2000\n",
    "batch_size = 4\n",
    "epochs=50\n",
    "train_size=train_size\n",
    "eval_size=eval_size\n",
    "output_activation=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training/evaluation data**\n",
    "\n",
    "The following is code to load training/evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def parse_function(proto):\n",
    "    \"\"\"The parsing function.\n",
    "    Read a serialized example into the structure defined by FEATURES_DICT.\n",
    "    Args:\n",
    "      example_proto: a serialized Example.\n",
    "    Returns: \n",
    "      A tuple of the predictors dictionary and the labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define your tfrecord \n",
    "    features = input_bands + output_bands\n",
    "    \n",
    "    # Specify the size and shape of patches expected by the model.\n",
    "    columns = [\n",
    "      tf.io.FixedLenFeature(shape=[1,1], dtype=tf.float32) for k in features\n",
    "    ]\n",
    "    \n",
    "    features_dict = dict(zip(features, columns))\n",
    "    \n",
    "    # Load one example\n",
    "    parsed_features = tf.io.parse_single_example(proto, features_dict)\n",
    "    \n",
    "    # Convert a dictionary of tensors to a tuple of (inputs, outputs)\n",
    "    inputsList = [parsed_features.get(key) for key in features]\n",
    "    stacked = tf.stack(inputsList, axis=0)\n",
    "    \n",
    "    # Convert the tensors into a stack in HWC shape\n",
    "    stacked = tf.transpose(stacked)\n",
    "    \n",
    "    return stacked[:,:,:len(input_bands)], stacked[:,:,len(input_bands):]\n",
    "\n",
    "def get_dataset(glob):\n",
    "    \"\"\"Get the dataset\n",
    "    Returns: \n",
    "    A tf.data.Dataset of training data.\n",
    "    \"\"\"\n",
    "    glob = tf.compat.v1.io.gfile.glob(glob)\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=5)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_training_dataset():\n",
    "    \"\"\"Get the preprocessed training dataset\n",
    "    Returns: \n",
    "    A tf.data.Dataset of training data.\n",
    "    \"\"\"\n",
    "    glob = 'gs://' + bucket + '/' + folder + '/' + base_names[0] + '*'\n",
    "    dataset = get_dataset(glob)\n",
    "    dataset = dataset.shuffle(shuffle_size).batch(batch_size).repeat()\n",
    "    return dataset\n",
    "\n",
    "def get_evaluation_dataset():\n",
    "    \"\"\"Get the preprocessed evaluation dataset\n",
    "    Returns: \n",
    "      A tf.data.Dataset of evaluation data.\n",
    "    \"\"\"\n",
    "    glob = 'gs://' + bucket + '/' + folder + '/' + base_names[1] + '*'\n",
    "    dataset = get_dataset(glob)\n",
    "    dataset = dataset.batch(1).repeat()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import Model # Keras model module\n",
    "from tensorflow.python.keras.layers import Input, Dense, Dropout, Activation \n",
    "\n",
    "def create_keras_model(inputShape, nClasses, output_activation='linear'):\n",
    "    \n",
    "    inputs = Input(shape=inputShape, name='vector')\n",
    " \n",
    "    x = Dense(32, input_shape=inputShape, activation='relu')(inputs)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(nClasses)(x)\n",
    "    \n",
    "    outputs = Activation(output_activation, name= 'output')(x)\n",
    "        \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='sequential')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training task**\n",
    "\n",
    "The following will get the training and evaluation data, train the model and save it when it's done in a Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "          \n",
    "def train_and_evaluate():\n",
    "    \"\"\"Trains and evaluates the Keras model.\n",
    "\n",
    "    Uses the Keras model defined in model.py and trains on data loaded and\n",
    "    preprocessed in util.py. Saves the trained model in TensorFlow SavedModel\n",
    "    format to the path defined in part by the --job-dir argument.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the Keras Model\n",
    "    if not output_activation:\n",
    "        keras_model = create_keras_model(inputShape = (None, None, len(input_bands)), nClasses = len(output_bands))\n",
    "    else:\n",
    "        keras_model = create_keras_model(inputShape = (None, None, len(input_bands)), nClasses = len(output_bands), output_activation = output_activation)\n",
    "\n",
    "    # Compile Keras model\n",
    "    keras_model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "\n",
    "\n",
    "    # Pass a tfrecord\n",
    "    training_dataset = get_training_dataset()\n",
    "    evaluation_dataset = get_evaluation_dataset()\n",
    "    \n",
    "    # Setup TensorBoard callback.\n",
    "    tensorboard_cb = tf.keras.callbacks.TensorBoard(logs_dir)\n",
    "\n",
    "    # Train model\n",
    "    keras_model.fit(\n",
    "        x=training_dataset,\n",
    "        steps_per_epoch=int(train_size / batch_size),\n",
    "        epochs=epochs,\n",
    "        validation_data=evaluation_dataset,\n",
    "        validation_steps=int(eval_size / batch_size),\n",
    "        verbose=1,\n",
    "        callbacks=[tensorboard_cb])\n",
    "    \n",
    "    tf.keras.models.save_model(keras_model, filepath=os.path.join(model_dir, str(int(time.time()))), save_format=\"tf\")\n",
    "    \n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 2022 steps, validate for 877 steps\n",
      "Epoch 1/50\n",
      "   1/2022 [..............................] - ETA: 36:44 - loss: 0.0110 - mean_squared_error: 0.0110WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (3.539397). Check your callbacks.\n",
      "2022/2022 [==============================] - 15s 7ms/step - loss: 83.2001 - mean_squared_error: 83.2309 - val_loss: 64.3992 - val_mean_squared_error: 64.3992\n",
      "Epoch 2/50\n",
      "2022/2022 [==============================] - 28s 14ms/step - loss: 78.7397 - mean_squared_error: 78.7687 - val_loss: 59.1074 - val_mean_squared_error: 59.1074\n",
      "Epoch 3/50\n",
      "2022/2022 [==============================] - 10s 5ms/step - loss: 78.1049 - mean_squared_error: 78.1339 - val_loss: 54.7844 - val_mean_squared_error: 54.7844\n",
      "Epoch 4/50\n",
      "2022/2022 [==============================] - 9s 4ms/step - loss: 64.1067 - mean_squared_error: 64.1305 - val_loss: 52.8855 - val_mean_squared_error: 52.8855\n",
      "Epoch 5/50\n",
      "2022/2022 [==============================] - 12s 6ms/step - loss: 65.9322 - mean_squared_error: 65.9566 - val_loss: 49.9769 - val_mean_squared_error: 49.9769\n",
      "Epoch 6/50\n",
      "2022/2022 [==============================] - 7s 3ms/step - loss: 64.9093 - mean_squared_error: 64.9334 - val_loss: 46.0060 - val_mean_squared_error: 46.0060\n",
      "Epoch 7/50\n",
      "2022/2022 [==============================] - 7s 3ms/step - loss: 59.9277 - mean_squared_error: 59.9500 - val_loss: 45.4808 - val_mean_squared_error: 45.4808\n",
      "Epoch 8/50\n",
      "2022/2022 [==============================] - 11s 6ms/step - loss: 60.2654 - mean_squared_error: 60.2877 - val_loss: 43.2340 - val_mean_squared_error: 43.2340\n",
      "Epoch 9/50\n",
      "2022/2022 [==============================] - 7s 4ms/step - loss: 61.9468 - mean_squared_error: 61.9697 - val_loss: 43.2755 - val_mean_squared_error: 43.2755\n",
      "Epoch 10/50\n",
      "2022/2022 [==============================] - 8s 4ms/step - loss: 60.1263 - mean_squared_error: 60.1486 - val_loss: 44.4449 - val_mean_squared_error: 44.4449\n",
      "Epoch 11/50\n",
      "2022/2022 [==============================] - 8s 4ms/step - loss: 68.2141 - mean_squared_error: 68.2394 - val_loss: 40.8561 - val_mean_squared_error: 40.8561\n",
      "Epoch 12/50\n",
      "2022/2022 [==============================] - 9s 4ms/step - loss: 55.4871 - mean_squared_error: 55.5077 - val_loss: 41.8557 - val_mean_squared_error: 41.8557\n",
      "Epoch 13/50\n",
      "2022/2022 [==============================] - 18s 9ms/step - loss: 58.3074 - mean_squared_error: 58.3290 - val_loss: 41.2392 - val_mean_squared_error: 41.2392\n",
      "Epoch 14/50\n",
      "2022/2022 [==============================] - 8s 4ms/step - loss: 62.9377 - mean_squared_error: 62.9610 - val_loss: 39.4673 - val_mean_squared_error: 39.4673\n",
      "Epoch 15/50\n",
      "2022/2022 [==============================] - 8s 4ms/step - loss: 52.0152 - mean_squared_error: 52.0330 - val_loss: 32.8405 - val_mean_squared_error: 32.8405\n",
      "Epoch 16/50\n",
      "2022/2022 [==============================] - 8s 4ms/step - loss: 55.8185 - mean_squared_error: 55.8392 - val_loss: 34.5340 - val_mean_squared_error: 34.5340\n",
      "Epoch 17/50\n",
      "2022/2022 [==============================] - 9s 5ms/step - loss: 58.6639 - mean_squared_error: 58.6857 - val_loss: 37.0712 - val_mean_squared_error: 37.0712\n",
      "Epoch 18/50\n",
      "2022/2022 [==============================] - 6s 3ms/step - loss: 61.4281 - mean_squared_error: 54.1492 - val_loss: 34.6674 - val_mean_squared_error: 34.6674\n",
      "Epoch 19/50\n",
      "2022/2022 [==============================] - 8s 4ms/step - loss: 56.6472 - mean_squared_error: 56.6683 - val_loss: 31.4451 - val_mean_squared_error: 31.4451\n",
      "Epoch 20/50\n",
      "2022/2022 [==============================] - 8s 4ms/step - loss: 52.6858 - mean_squared_error: 52.7053 - val_loss: 30.1258 - val_mean_squared_error: 30.1258\n",
      "Epoch 21/50\n",
      "2022/2022 [==============================] - 7s 3ms/step - loss: 53.4791 - mean_squared_error: 53.4989 - val_loss: 32.4835 - val_mean_squared_error: 32.4835\n",
      "Epoch 22/50\n",
      "2022/2022 [==============================] - 10s 5ms/step - loss: 52.6867 - mean_squared_error: 51.6206 - val_loss: 33.0613 - val_mean_squared_error: 33.0613\n",
      "Epoch 23/50\n",
      "2022/2022 [==============================] - 8s 4ms/step - loss: 51.0708 - mean_squared_error: 51.0897 - val_loss: 28.4322 - val_mean_squared_error: 28.4322\n",
      "Epoch 24/50\n",
      "2022/2022 [==============================] - 5s 2ms/step - loss: 48.4817 - mean_squared_error: 48.4997 - val_loss: 26.6276 - val_mean_squared_error: 26.6276\n",
      "Epoch 25/50\n",
      "2022/2022 [==============================] - 15s 7ms/step - loss: 40.9348 - mean_squared_error: 40.9500 - val_loss: 23.2825 - val_mean_squared_error: 23.2825\n",
      "Epoch 26/50\n",
      "2022/2022 [==============================] - 9s 4ms/step - loss: 48.1200 - mean_squared_error: 48.1378 - val_loss: 22.9047 - val_mean_squared_error: 22.9047\n",
      "Epoch 27/50\n",
      "2022/2022 [==============================] - 13s 6ms/step - loss: 38.1358 - mean_squared_error: 38.1500 - val_loss: 22.1093 - val_mean_squared_error: 22.1093\n",
      "Epoch 28/50\n",
      "2022/2022 [==============================] - 9s 4ms/step - loss: 41.3039 - mean_squared_error: 41.3192 - val_loss: 20.6742 - val_mean_squared_error: 20.6742\n",
      "Epoch 29/50\n",
      "2022/2022 [==============================] - 6s 3ms/step - loss: 55.5983 - mean_squared_error: 55.6182 - val_loss: 22.4796 - val_mean_squared_error: 22.4796\n",
      "Epoch 30/50\n",
      "2022/2022 [==============================] - 5s 3ms/step - loss: 47.1700 - mean_squared_error: 47.1874 - val_loss: 18.7321 - val_mean_squared_error: 18.7321\n",
      "Epoch 31/50\n",
      "2022/2022 [==============================] - 13s 7ms/step - loss: 37.0061 - mean_squared_error: 37.0198 - val_loss: 18.1387 - val_mean_squared_error: 18.1387\n",
      "Epoch 32/50\n",
      "2022/2022 [==============================] - 5s 3ms/step - loss: 38.3234 - mean_squared_error: 38.3376 - val_loss: 17.2121 - val_mean_squared_error: 17.2121\n",
      "Epoch 33/50\n",
      "2022/2022 [==============================] - 6s 3ms/step - loss: 35.8868 - mean_squared_error: 35.9001 - val_loss: 13.4702 - val_mean_squared_error: 13.4702\n",
      "Epoch 34/50\n",
      "2022/2022 [==============================] - 7s 4ms/step - loss: 39.1125 - mean_squared_error: 39.1271 - val_loss: 14.8563 - val_mean_squared_error: 14.8563\n",
      "Epoch 35/50\n",
      "2022/2022 [==============================] - 9s 4ms/step - loss: 35.0492 - mean_squared_error: 35.0621 - val_loss: 7.9853 - val_mean_squared_error: 7.9853\n",
      "Epoch 36/50\n",
      "2022/2022 [==============================] - 9s 4ms/step - loss: 32.7854 - mean_squared_error: 32.7975 - val_loss: 5.5603 - val_mean_squared_error: 5.5603\n",
      "Epoch 37/50\n",
      "2022/2022 [==============================] - 8s 4ms/step - loss: 28.6975 - mean_squared_error: 28.7081 - val_loss: 9.9096 - val_mean_squared_error: 9.9096\n",
      "Epoch 38/50\n",
      "2022/2022 [==============================] - 5s 3ms/step - loss: 32.4937 - mean_squared_error: 32.5058 - val_loss: 8.3113 - val_mean_squared_error: 8.3113\n",
      "Epoch 39/50\n",
      "2022/2022 [==============================] - 10s 5ms/step - loss: 28.3869 - mean_squared_error: 28.3974 - val_loss: 15.2752 - val_mean_squared_error: 15.2752\n",
      "Epoch 40/50\n",
      "2022/2022 [==============================] - 7s 3ms/step - loss: 31.6952 - mean_squared_error: 31.7070 - val_loss: 6.0550 - val_mean_squared_error: 6.0550\n",
      "Epoch 41/50\n",
      "2022/2022 [==============================] - 8s 4ms/step - loss: 24.0169 - mean_squared_error: 24.0259 - val_loss: 6.6364 - val_mean_squared_error: 6.6364\n",
      "Epoch 42/50\n",
      "2022/2022 [==============================] - 6s 3ms/step - loss: 28.1696 - mean_squared_error: 28.1800 - val_loss: 3.9832 - val_mean_squared_error: 3.9832\n",
      "Epoch 43/50\n",
      "2022/2022 [==============================] - 9s 5ms/step - loss: 27.9051 - mean_squared_error: 27.9154 - val_loss: 6.5917 - val_mean_squared_error: 6.5917\n",
      "Epoch 44/50\n",
      "2022/2022 [==============================] - 8s 4ms/step - loss: 36.0532 - mean_squared_error: 36.0665 - val_loss: 9.1431 - val_mean_squared_error: 9.1431\n",
      "Epoch 45/50\n",
      "2022/2022 [==============================] - 7s 3ms/step - loss: 34.9575 - mean_squared_error: 34.9704 - val_loss: 2.6993 - val_mean_squared_error: 2.6993\n",
      "Epoch 46/50\n",
      "2022/2022 [==============================] - 10s 5ms/step - loss: 23.5416 - mean_squared_error: 23.5503 - val_loss: 11.6222 - val_mean_squared_error: 11.6222\n",
      "Epoch 47/50\n",
      "2022/2022 [==============================] - 6s 3ms/step - loss: 31.2373 - mean_squared_error: 31.2488 - val_loss: 3.7480 - val_mean_squared_error: 3.7480\n",
      "Epoch 48/50\n",
      "2022/2022 [==============================] - 8s 4ms/step - loss: 25.8300 - mean_squared_error: 25.8396 - val_loss: 2.2407 - val_mean_squared_error: 2.2407\n",
      "Epoch 49/50\n",
      "2022/2022 [==============================] - 6s 3ms/step - loss: 25.2008 - mean_squared_error: 25.2070 - val_loss: 2.5820 - val_mean_squared_error: 2.5820\n",
      "Epoch 50/50\n",
      "2022/2022 [==============================] - 5s 2ms/step - loss: 26.1330 - mean_squared_error: 26.1426 - val_loss: 4.6872 - val_mean_squared_error: 4.6872\n",
      "INFO:tensorflow:Assets written to: gs://skydipper_materials/cnn-models/Sentinel2_WaterQuality/trainer/model/1580817124/assets\n"
     ]
    }
   ],
   "source": [
    "model = train_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877/877 [==============================] - 1s 1ms/step - loss: 4.6872 - mean_squared_error: 4.6872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.687214184393426, 4.687213]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_dataset = get_evaluation_dataset()\n",
    "model.evaluate(evaluation_dataset, steps=int(eval_size / batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_dir = 'gs://' + env.bucket_name + '/' + 'cnn-models/' + dataset_name + '/trainer'\n",
    "model_dir = job_dir + '/model'\n",
    "PROJECT_ID = env.project_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the directory with the latest timestamp, in case you've trained multiple times\n",
    "exported_model_dirs = ! gsutil ls {model_dir}\n",
    "saved_model_path = exported_model_dirs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Predict in Earth Engine\n",
    "\n",
    "### Prepare the model for making predictions in Earth Engine\n",
    "\n",
    "Before we can use the model in Earth Engine, it needs to be hosted by AI Platform.  But before we can host the model on AI Platform we need to *EEify* (a new word!) it.  The EEification process merely appends some extra operations to the input and outputs of the model in order to accomdate the interchange format between pixels from Earth Engine (float32) and inputs to AI Platform (base64).  (See [this doc](https://cloud.google.com/ml-engine/docs/online-predict#binary_data_in_prediction_input) for details.)  \n",
    "\n",
    "**`earthengine model prepare`**\n",
    "\n",
    "The EEification process is handled for you using the Earth Engine command `earthengine model prepare`.  To use that command, we need to specify the input and output model directories and the name of the input and output nodes in the TensorFlow computation graph.  We can do all that programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Sentinel2_WaterQuality'\n",
    "job_dir = 'gs://' + env.bucket_name + '/' + 'cnn-models/' + dataset_name + '/trainer'\n",
    "model_dir = job_dir + '/model'\n",
    "project_id = env.project_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the directory with the latest timestamp, in case you've trained multiple times\n",
    "exported_model_dirs = ! gsutil ls {model_dir}\n",
    "saved_model_path = exported_model_dirs[-1]\n",
    "\n",
    "folder_name = saved_model_path.split('/')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command using Cloud API.  Set --no-use_cloud_api to go back to using the API\n",
      "\n",
      "Successfully saved project id\n",
      "Running command using Cloud API.  Set --no-use_cloud_api to go back to using the API\n",
      "\n",
      "Success: model at 'gs://skydipper_materials/cnn-models/Sentinel2_WaterQuality/trainer/eeified/1580824709' is ready to be hosted in AI Platform.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.tools import saved_model_utils\n",
    "\n",
    "meta_graph_def = saved_model_utils.get_meta_graph_def(saved_model_path, 'serve')\n",
    "inputs = meta_graph_def.signature_def['serving_default'].inputs\n",
    "outputs = meta_graph_def.signature_def['serving_default'].outputs\n",
    "\n",
    "# Just get the first thing(s) from the serving signature def.  i.e. this\n",
    "# model only has a single input and a single output.\n",
    "input_name = None\n",
    "for k,v in inputs.items():\n",
    "    input_name = v.name\n",
    "    break\n",
    "\n",
    "output_name = None\n",
    "for k,v in outputs.items():\n",
    "    output_name = v.name\n",
    "    break\n",
    "\n",
    "# Make a dictionary that maps Earth Engine outputs and inputs to \n",
    "# AI Platform inputs and outputs, respectively.\n",
    "import json\n",
    "input_dict = \"'\" + json.dumps({input_name: \"array\"}) + \"'\"\n",
    "output_dict = \"'\" + json.dumps({output_name: \"prediction\"}) + \"'\"\n",
    "\n",
    "# Put the EEified model next to the trained model directory.\n",
    "EEIFIED_DIR = job_dir + '/eeified/' + folder_name\n",
    "\n",
    "# You need to set the project before using the model prepare command.\n",
    "!earthengine set_project {PROJECT_ID}\n",
    "!earthengine model prepare --source_dir {saved_model_path} --dest_dir {EEIFIED_DIR} --input {input_dict} --output {output_dict}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployed the model to AI Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authenticate your GCP account**\n",
    "\n",
    "Enter the path to your service account key as the\n",
    "`GOOGLE_APPLICATION_CREDENTIALS` variable in the cell below and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GOOGLE_APPLICATION_CREDENTIALS=/Users/ikersanchez/Vizzuality/Keys/Skydipper/skydipper-196010-a4ce18e66917.json\n"
     ]
    }
   ],
   "source": [
    "%env GOOGLE_APPLICATION_CREDENTIALS {env.privatekey_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'water_quality_test'\n",
    "version_name = 'v' + folder_name\n",
    "project_id = env.project_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model: water_quality_test\n",
      "There was an error creating the model. Check the details:\n",
      "Field: model.name Error: A model with the same name already exists.\n"
     ]
    }
   ],
   "source": [
    "print('Creating model: ' + model_name)\n",
    "\n",
    "# Store your full project ID in a variable in the format the API needs.\n",
    "project = 'projects/{}'.format(project_id)\n",
    "\n",
    "# Build a representation of the Cloud ML API.\n",
    "ml = discovery.build('ml', 'v1')\n",
    "\n",
    "# Create a dictionary with the fields from the request body.\n",
    "request_dict = {'name': model_name,\n",
    "               'description': ''}\n",
    "\n",
    "# Create a request to call projects.models.create.\n",
    "request = ml.projects().models().create(\n",
    "              parent=project, body=request_dict)\n",
    "\n",
    "# Make the call.\n",
    "try:\n",
    "    response = request.execute()\n",
    "    print(response)\n",
    "except errors.HttpError as err:\n",
    "    # Something went wrong, print out some information.\n",
    "    print('There was an error creating the model. Check the details:')\n",
    "    print(err._get_reason())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'projects/skydipper-196010/operations/create_water_quality_test_v1580824709-1580824821325', 'metadata': {'@type': 'type.googleapis.com/google.cloud.ml.v1.OperationMetadata', 'createTime': '2020-02-04T14:00:22Z', 'operationType': 'CREATE_VERSION', 'modelName': 'projects/skydipper-196010/models/water_quality_test', 'version': {'name': 'projects/skydipper-196010/models/water_quality_test/versions/v1580824709', 'deploymentUri': 'gs://skydipper_materials/cnn-models/Sentinel2_WaterQuality/trainer/eeified/1580824709', 'createTime': '2020-02-04T14:00:21Z', 'runtimeVersion': '1.14', 'autoScaling': {'minNodes': 10}, 'etag': 'NbCwe2E94o0=', 'framework': 'TENSORFLOW', 'machineType': 'mls1-c4-m2', 'pythonVersion': '3.5'}}}\n"
     ]
    }
   ],
   "source": [
    "ml = discovery.build('ml', 'v1')\n",
    "request_dict = {\n",
    "    'name': version_name,\n",
    "    'deploymentUri': EEIFIED_DIR,\n",
    "    'runtimeVersion': '1.14',\n",
    "    'pythonVersion': '3.5',\n",
    "    'framework': 'TENSORFLOW',\n",
    "    'autoScaling': {\n",
    "        \"minNodes\": 10\n",
    "    },\n",
    "    'machineType': 'mls1-c4-m2'\n",
    "}\n",
    "request = ml.projects().models().versions().create(\n",
    "    parent=f'projects/{project_id}/models/{model_name}',\n",
    "    body=request_dict\n",
    ")\n",
    "\n",
    "# Make the call.\n",
    "try:\n",
    "    response = request.execute()\n",
    "    print(response)\n",
    "except errors.HttpError as err:\n",
    "    # Something went wrong, print out some information.\n",
    "    print('There was an error creating the model. Check the details:')\n",
    "    print(err._get_reason())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check deployment status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_status_deployment(model_name, version_name):\n",
    "    desc = !gcloud ai-platform versions describe {version_name} --model={model_name}\n",
    "    return desc.grep('state:')[0].split(':')[1].strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READY\n"
     ]
    }
   ],
   "source": [
    "print(check_status_deployment(model_name, version_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the trained model and use it for prediction in Earth Engine\n",
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polygon where we want to display de predictions\n",
    "geometry = {\n",
    "  \"type\": \"FeatureCollection\",\n",
    "  \"features\": [\n",
    "    {\n",
    "      \"type\": \"Feature\",\n",
    "      \"properties\": {},\n",
    "      \"geometry\": {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [\n",
    "          [\n",
    "            [\n",
    "              -2.63671875,\n",
    "              34.56085936708384\n",
    "            ],\n",
    "            [\n",
    "              -1.2084960937499998,\n",
    "              34.56085936708384\n",
    "            ],\n",
    "            [\n",
    "              -1.2084960937499998,\n",
    "              36.146746777814364\n",
    "            ],\n",
    "            [\n",
    "              -2.63671875,\n",
    "              36.146746777814364\n",
    "            ],\n",
    "            [\n",
    "              -2.63671875,\n",
    "              34.56085936708384\n",
    "            ]\n",
    "          ]\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input image**\n",
    "\n",
    "Select bands and convert them into float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = images[0].select(bands[0]).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Image',\n",
       " 'bands': [{'id': 'turbidity_blended_mean',\n",
       "   'data_type': {'type': 'PixelType', 'precision': 'float'},\n",
       "   'crs': 'EPSG:4326',\n",
       "   'crs_transform': [0.0008983152841195215,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0008983152841195215,\n",
       "    0.0]}]}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained model and use it for prediction.\n",
    "model = ee.Model.fromAiPlatformPredictor(\n",
    "    projectName = project_id,\n",
    "    modelName = model_name,\n",
    "    version = version_name,\n",
    "    inputTileSize = [1, 1],\n",
    "    inputOverlapSize = [0, 0],\n",
    "    proj = ee.Projection('EPSG:4326').atScale(scale),\n",
    "    fixInputProj = True,\n",
    "    outputBands = {'prediction': {\n",
    "        'type': ee.PixelType.float(),\n",
    "        'dimensions': 1,\n",
    "      }                  \n",
    "    }\n",
    ")\n",
    "predictions = model.predictImage(image.toArray()).arrayFlatten([bands[1]])\n",
    "predictions.getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clip the prediction area with the polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip the prediction area with the polygon\n",
    "polygon = ee.Geometry.Polygon(geometry.get('features')[0].get('geometry').get('coordinates'))\n",
    "predictions = predictions.clip(polygon)\n",
    "\n",
    "# Get centroid\n",
    "centroid = polygon.centroid().getInfo().get('coordinates')[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display**\n",
    "\n",
    "Use folium to visualize the input imagery and the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x1429225c0>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the URL format used for Earth Engine generated map tiles.\n",
    "EE_TILES = 'https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}'\n",
    "\n",
    "mapid = image.getMapId({'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 1})\n",
    "map = folium.Map(location=centroid, zoom_start=8)\n",
    "folium.TileLayer(\n",
    "    tiles=EE_TILES.format(**mapid),\n",
    "    attr='Google Earth Engine',\n",
    "    overlay=True,\n",
    "    name='median composite',\n",
    "  ).add_to(map)\n",
    "\n",
    "params = ee_collection_specifics.vizz_params(collections[1])[0]\n",
    "mapid = images[1].getMapId(params)\n",
    "folium.TileLayer(\n",
    "    tiles=EE_TILES.format(**mapid),\n",
    "    attr='Google Earth Engine',\n",
    "    overlay=True,\n",
    "    name=str(params['bands']),\n",
    "  ).add_to(map)\n",
    "\n",
    "for band in bands[1]:\n",
    "    mapid = predictions.getMapId({'bands': [band], 'min': 0, 'max': 1})\n",
    "    \n",
    "    folium.TileLayer(\n",
    "        tiles=EE_TILES.format(**mapid),\n",
    "        attr='Google Earth Engine',\n",
    "        overlay=True,\n",
    "        name=band,\n",
    "      ).add_to(map)\n",
    " \n",
    "map.add_child(folium.LayerControl())\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions of an image outside Earth Engine\n",
    "### Export the imagery\n",
    "\n",
    "We export the imagery using TFRecord format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input image\n",
    "image = images[0].select(bands[0])\n",
    "\n",
    "dataset_name = 'Sentinel2_WaterQuality'\n",
    "file_name = 'image_pixel'\n",
    "bucket = env.bucket_name\n",
    "folder = 'cnn-models/'+dataset_name+'/data'\n",
    "\n",
    "# polygon where we want to display de predictions\n",
    "geometry = {\n",
    "  \"type\": \"FeatureCollection\",\n",
    "  \"features\": [\n",
    "    {\n",
    "      \"type\": \"Feature\",\n",
    "      \"properties\": {},\n",
    "      \"geometry\": {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [\n",
    "          [\n",
    "            [\n",
    "              -2.63671875,\n",
    "              34.56085936708384\n",
    "            ],\n",
    "            [\n",
    "              -1.2084960937499998,\n",
    "              34.56085936708384\n",
    "            ],\n",
    "            [\n",
    "              -1.2084960937499998,\n",
    "              36.146746777814364\n",
    "            ],\n",
    "            [\n",
    "              -2.63671875,\n",
    "              36.146746777814364\n",
    "            ],\n",
    "            [\n",
    "              -2.63671875,\n",
    "              34.56085936708384\n",
    "            ]\n",
    "          ]\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify patch and file dimensions.\n",
    "imageExportFormatOptions = {\n",
    "  'patchDimensions': [256, 256],\n",
    "  'maxFileSize': 104857600,\n",
    "  'compressed': True\n",
    "}\n",
    "\n",
    "# Setup the task.\n",
    "imageTask = ee.batch.Export.image.toCloudStorage(\n",
    "  image=image,\n",
    "  description='Image Export',\n",
    "  fileNamePrefix=folder + '/' + file_name,\n",
    "  bucket=bucket,\n",
    "  scale=scale,\n",
    "  fileFormat='TFRecord',\n",
    "  region=geometry.get('features')[0].get('geometry').get('coordinates'),\n",
    "  formatOptions=imageExportFormatOptions,\n",
    ")\n",
    "\n",
    "# Start the task.\n",
    "imageTask.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the JSON mixer file**\n",
    "\n",
    "The mixer contains metadata and georeferencing information for the exported patches, each of which is in a different file. Read the mixer to get some information needed for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = f'gs://{bucket}' + '/' + folder + '/' + file_name +'.json'\n",
    "\n",
    "# Load the contents of the mixer file to a JSON object.\n",
    "json_text = !gsutil cat {json_file}\n",
    "\n",
    "# Get a single string w/ newlines from the IPython.utils.text.SList\n",
    "mixer = json.loads(json_text.nlstr)\n",
    "pprint(mixer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the image files into a dataset**\n",
    "\n",
    "The input needs to be preprocessed differently than the training and testing.  Mainly, this is because the pixels are written into records as patches, we need to read the patches in as one big tensor (one patch for each band), then flatten them into lots of little tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relevant info from the JSON mixer file.\n",
    "PATCH_WIDTH = mixer['patchDimensions'][0]\n",
    "PATCH_HEIGHT = mixer['patchDimensions'][1]\n",
    "PATCHES = mixer['totalPatches']\n",
    "PATCH_DIMENSIONS_FLAT = [PATCH_WIDTH * PATCH_HEIGHT, 1]\n",
    "features = bands[0]\n",
    "\n",
    "glob = f'gs://{bucket}' + '/' + folder + '/' + file_name +'.tfrecord.gz'\n",
    "\n",
    "# Note that the tensors are in the shape of a patch, one patch for each band.\n",
    "image_columns = [\n",
    "  tf.FixedLenFeature(shape=PATCH_DIMENSIONS_FLAT, dtype=tf.float32) for k in features\n",
    "]\n",
    "\n",
    "# Parsing dictionary.\n",
    "features_dict = dict(zip(bands[0], image_columns))\n",
    "\n",
    "def parse_image(proto):\n",
    "    return tf.io.parse_single_example(proto, features_dict)\n",
    "\n",
    "image_dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
    "\n",
    "image_dataset = image_dataset.map(parse_image, num_parallel_calls=5)\n",
    "\n",
    "# Break our long tensors into many little ones.\n",
    "image_dataset = image_dataset.flat_map(\n",
    "    lambda features: tf.data.Dataset.from_tensor_slices(features)\n",
    ")\n",
    "    \n",
    "# Turn the dictionary in each record into a tuple without a label.\n",
    "image_dataset = image_dataset.map(\n",
    "    lambda dataDict: (tf.transpose(list(dataDict.values())), )\n",
    ")\n",
    "\n",
    "# Turn each patch into a batch.\n",
    "image_dataset = image_dataset.batch(PATCH_WIDTH * PATCH_HEIGHT)\n",
    "\n",
    "image_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the first record**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = iter(image_dataset.take(1)).next()\n",
    "input_arr = arr[0].numpy()\n",
    "print(input_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display the input channels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_channels(data, nChannels, titles = False):\n",
    "    if nChannels == 1:\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.imshow(data[:,:,0])\n",
    "        if titles:\n",
    "            plt.title(titles[0])\n",
    "    else:\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=nChannels, figsize=(5*nChannels,5))\n",
    "        for i in range(nChannels):\n",
    "            ax = axs[i]\n",
    "            ax.imshow(data[:,:,i])\n",
    "            if titles:\n",
    "                ax.set_title(titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_arr = input_arr.reshape((PATCH_WIDTH, PATCH_HEIGHT, len(bands[0])))\n",
    "input_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_channels(input_arr, input_arr.shape[2], titles=bands[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions for the image pixels\n",
    "\n",
    "To get predictions in each pixel, run the image dataset through the trained model using model.predict(). Print the first prediction to see that the output is a list of the three class probabilities for each pixel. Running all predictions might take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(image_dataset, steps=PATCHES, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_arr = predictions.reshape((PATCHES, PATCH_WIDTH, PATCH_HEIGHT, len(bands[1])))\n",
    "output_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_channels(output_arr[9,:,:,:], output_arr.shape[3], titles=bands[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the predictions to a TFRecord file\n",
    "\n",
    "We need to write the pixels into the file as patches in the same order they came out.  The records are written as serialized `tf.train.Example` protos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Sentinel2_WaterQuality'\n",
    "bucket = env.bucket_name\n",
    "folder = 'cnn-models/'+dataset_name+'/data'\n",
    "\n",
    "output_file = 'gs://' + bucket + '/' + folder + '/predicted_image_pixel.TFRecord'\n",
    "print('Writing to file ' + output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the writer.\n",
    "writer = tf.io.TFRecordWriter(output_file)\n",
    "\n",
    "patch = [[]]\n",
    "nPatch = 1\n",
    "for prediction in predictions:\n",
    "    patch[0].append(prediction[0][0])\n",
    "    # Once we've seen a patches-worth of class_ids...\n",
    "    if (len(patch[0]) == PATCH_WIDTH * PATCH_HEIGHT):\n",
    "        print('Done with patch ' + str(nPatch) + ' of ' + str(PATCHES))\n",
    "        # Create an example\n",
    "        example = tf.train.Example(\n",
    "            features=tf.train.Features(\n",
    "              feature={\n",
    "                'prediction': tf.train.Feature(\n",
    "                    float_list=tf.train.FloatList(\n",
    "                        value=patch[0]))\n",
    "              }\n",
    "            )\n",
    "          )\n",
    "        # Write the example to the file and clear our patch array so it's ready for\n",
    "        # another batch of class ids\n",
    "        writer.write(example.SerializeToString())\n",
    "        patch = [[]]\n",
    "        nPatch += 1\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify the existence of the predictions file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls -l {output_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the predicted image to an Earth Engine asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_id = 'projects/vizzuality/skydipper-water-quality/predicted-image' \n",
    "print('Writing to ' + asset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the upload.\n",
    "!earthengine upload image --asset_id={asset_id} {output_file} {json_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the predicted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get centroid\n",
    "polygon = ee.Geometry.Polygon(geometry.get('features')[0].get('geometry').get('coordinates'))\n",
    "\n",
    "centroid = polygon.centroid().getInfo().get('coordinates')[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EE_TILES = 'https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}'\n",
    "\n",
    "map = folium.Map(location=centroid, zoom_start=8)\n",
    "for n, collection in enumerate(collections):\n",
    "    params = ee_collection_specifics.vizz_params(collection)[0]\n",
    "    mapid = images[n].getMapId(params)\n",
    "    folium.TileLayer(\n",
    "        tiles=EE_TILES.format(**mapid),\n",
    "        attr='Google Earth Engine',\n",
    "        overlay=True,\n",
    "        name=str(params['bands']),\n",
    "      ).add_to(map)\n",
    "        \n",
    "        \n",
    "# Read predicted Image\n",
    "predicted_image = ee.Image(asset_id)\n",
    "                           \n",
    "mapid = predicted_image.getMapId({'bands': ['prediction'], 'min': 0, 'max': 1})\n",
    "folium.TileLayer(\n",
    "    tiles=EE_TILES.format(**mapid),\n",
    "    attr='Google Earth Engine',\n",
    "    overlay=True,\n",
    "    name='predicted image',\n",
    "  ).add_to(map)\n",
    "                           \n",
    "map.add_child(folium.LayerControl())\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
